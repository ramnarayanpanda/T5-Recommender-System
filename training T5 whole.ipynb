{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":26813,"status":"ok","timestamp":1739957084172,"user":{"displayName":"Ram Narayan Panda","userId":"07583152654448028535"},"user_tz":-330},"id":"8eJmgYWTXwRK","outputId":"cd5c4798-8f9e-4baf-d3f3-461a6e59ca1e"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","source":[],"metadata":{"id":"6o4K3bS4MIKs"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"09JVeY8_MINh"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"DQje-IQBYRvD"},"outputs":[],"source":["import numpy as np\n","import torch\n","import pickle\n","import json\n","import gzip\n","import random\n","import os\n","import re\n","import sentencepiece as spm\n","from collections import defaultdict\n","import copy\n","from tqdm import tqdm\n","from typing import Any, Callable, Dict, Iterable, List, Optional, Tuple\n","import logging\n","from pprint import pprint\n","import collections\n","\n","import torch\n","import torch.nn as nn\n","from torch.nn import CrossEntropyLoss\n","from torch.utils.data import DataLoader, Dataset, Sampler\n","\n","from dataclasses import dataclass\n","from transformers.models.t5.modeling_t5 import (\n","    T5Stack, T5Block, T5LayerNorm, T5LayerSelfAttention, T5LayerFF, T5LayerCrossAttention,\n","    T5PreTrainedModel, T5ForConditionalGeneration\n",")\n","from transformers import T5Config, T5Tokenizer, PreTrainedTokenizer\n","from transformers.modeling_outputs import ModelOutput, BaseModelOutput, BaseModelOutputWithPast, BaseModelOutputWithPastAndCrossAttentions, Seq2SeqLMOutput, Seq2SeqModelOutput\n","from transformers.utils import logging\n","from transformers.optimization import AdamW, get_linear_schedule_with_warmup\n","\n","random.seed(42)\n","torch.manual_seed(42)\n","\n","\n","DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"IlwG7ULaZg0-"},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"id":"2mzSRJReZhRU"},"source":["#### Params"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"H1V7kI1wZjN4"},"outputs":[],"source":["class ModelParams:\n","    seed = 42\n","    model_name = \"t5-base\"\n","    tokenizer = \"p5\"\n","    whole_word_embed = True\n","    max_text_length = 256\n","    do_lower_case = True\n","    batch_size = 4\n","    optimizer = torch.optim.Adam\n","    warmup_ratio = 0.05\n","    weight_decay = 0.01\n","    clip_grad_norm = -1.0\n","    gradient_accumulation_steps = 1\n","    lr = 1e-3\n","    adam_eps = 1e-6\n","    adam_beta1 = 0.9\n","    adam_beta2 = 0.999\n","    epoch = 1\n","    dropout = 0.1\n","    losses = ['rating_loss', 'sequential_loss', 'review_loss', 'metadata_loss', 'recommend_loss', 'total_loss']\n","\n","    # inference params\n","    gen_max_length = 64"]},{"cell_type":"markdown","metadata":{"id":"SvMMpJuHZmdC"},"source":["#### Data Template"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"cGga-Z7fX4sY"},"outputs":[],"source":["'''\n","Pretraining Tasks -- 5 Prompt Families (1, 2, 3, 4, 5)\n","'''\n","\n","all_tasks = {}\n","\n","# =====================================================\n","# Task Subgroup 1 -- Rating -- 10 Prompts\n","# =====================================================\n","\n","task_subgroup_1 = {}\n","\n","template = {}\n","\n","'''\n","Input template:\n","Which star rating will user {{user_id}} give item {{item_id}}? (1 being lowest and 5 being highest)\n","\n","\n","Target template:\n","{{star_rating}}\n","\n","\n","Metrics:\n","Accuracy\n","'''\n","\n","template['source'] = \"Which star rating will user_{} give item_{} ? ( 1 being lowest and 5 being highest )\"\n","template['target'] = \"{}\"\n","template['task'] = \"rating\"\n","template['source_argc'] = 2\n","template['source_argv'] = ['user_id', 'item_id']\n","template['target_argc'] = 1\n","template['target_argv'] = ['star_rating']\n","template['id'] = \"1-1\"\n","\n","task_subgroup_1[\"1-1\"] = template\n","\n","template = {}\n","'''\n","Input template:\n","How will user {{user_id}} rate this business: {{item_title}}? (1 being lowest and 5 being highest)\n","\n","\n","Target template:\n","{{star_rating}}\n","\n","\n","Metrics:\n","Accuracy\n","'''\n","template['source'] = \"How will user_{} rate this business : {} ? ( 1 being lowest and 5 being highest )\"\n","template['target'] = \"{}\"\n","template['task'] = \"rating\"\n","template['source_argc'] = 2\n","template['source_argv'] = ['user_id', 'item_title']\n","template['target_argc'] = 1\n","template['target_argv'] = ['star_rating']\n","template['id'] = \"1-2\"\n","\n","task_subgroup_1[\"1-2\"] = template\n","\n","template = {}\n","'''\n","Input template:\n","Will user {{user_id}} give item {{item_id}} a {{star_rating}}-star rating? (1 being lowest and 5 being highest)\n","\n","\n","Target template:\n","{{answer_choices[label]}} (yes/no)\n","\n","\n","Metrics:\n","Accuracy\n","'''\n","template['source'] = \"Will user_{} give item_{} a {}-star rating ? ( 1 being lowest and 5 being highest )\"\n","template['target'] = \"{}\"\n","template['task'] = \"rating\"\n","template['source_argc'] = 3\n","template['source_argv'] = ['user_id', 'item_id', 'star_rating']\n","template['target_argc'] = 1\n","template['target_argv'] = ['yes_no']\n","template['id'] = \"1-3\"\n","\n","task_subgroup_1[\"1-3\"] = template\n","\n","template = {}\n","'''\n","Input template:\n","Does user {{user_id}} like or dislike item {{item_id}}?\n","\n","\n","Target template:\n","{{answer_choices[label]}} (like/dislike) – like (4,5) / dislike (1,2,3)\n","\n","Metrics:\n","Accuracy\n","'''\n","template['source'] = \"Does user_{} like or dislike item_{} ?\"\n","template['target'] = \"{}\"\n","template['task'] = \"rating\"\n","template['source_argc'] = 2\n","template['source_argv'] = ['user_id', 'item_id']\n","template['target_argc'] = 1\n","template['target_argv'] = ['like_dislike']\n","template['id'] = \"1-4\"\n","\n","task_subgroup_1[\"1-4\"] = template\n","\n","template = {}\n","'''\n","Input template:\n","Predict the user {{user_id}}’s preference on item {{item_id}} ({{item_title}})\n","-1\n","-2\n","-3\n","-4\n","-5\n","\n","Target template:\n","{{answer_choices[star_rating-1]}}\n","\n","Metrics:\n","Accuracy\n","'''\n","template['source'] = \"Predict the user_{}’s preference on item_{} ( {} ) \\n -1 \\n -2 \\n -3 \\n -4 \\n -5\"\n","template['target'] = \"{}\"\n","template['task'] = \"rating\"\n","template['source_argc'] = 3\n","template['source_argv'] = ['user_id', 'item_id', 'item_title']\n","template['target_argc'] = 1\n","template['target_argv'] = ['star_rating']\n","template['id'] = \"1-5\"\n","\n","task_subgroup_1[\"1-5\"] = template\n","\n","template = {}\n","\n","'''\n","Input template:\n","What star rating do you think {{user_desc}} will give item {{item_id}}? (1 being lowest and 5 being highest)\n","\n","\n","Target template:\n","{{star_rating}}\n","\n","\n","Metrics:\n","Accuracy\n","'''\n","\n","template['source'] = \"What star rating do you think {} will give item_{} ? ( 1 being lowest and 5 being highest )\"\n","template['target'] = \"{}\"\n","template['task'] = \"rating\"\n","template['source_argc'] = 2\n","template['source_argv'] = ['user_desc', 'item_id']\n","template['target_argc'] = 1\n","template['target_argv'] = ['star_rating']\n","template['id'] = \"1-6\"\n","\n","task_subgroup_1[\"1-6\"] = template\n","\n","template = {}\n","'''\n","Input template:\n","How will {{user_desc}} rate this business: {{item_title}}? (1 being lowest and 5 being highest)\n","\n","\n","Target template:\n","{{star_rating}}\n","\n","\n","Metrics:\n","Accuracy\n","'''\n","template['source'] = \"How will {} rate this business : {} ? ( 1 being lowest and 5 being highest )\"\n","template['target'] = \"{}\"\n","template['task'] = \"rating\"\n","template['source_argc'] = 2\n","template['source_argv'] = ['user_desc', 'item_title']\n","template['target_argc'] = 1\n","template['target_argv'] = ['star_rating']\n","template['id'] = \"1-7\"\n","\n","task_subgroup_1[\"1-7\"] = template\n","\n","template = {}\n","'''\n","Input template:\n","Will {{user_desc}} give a {{star_rating}}-star rating for {{item_title}}? (1 being lowest and 5 being highest)\n","\n","\n","Target template:\n","{{answer_choices[label]}} (yes/no)\n","\n","\n","Metrics:\n","Accuracy\n","'''\n","template['source'] = \"Will {} give a {}-star rating for {} ? ( 1 being lowest and 5 being highest )\"\n","template['target'] = \"{}\"\n","template['task'] = \"rating\"\n","template['source_argc'] = 3\n","template['source_argv'] = ['user_desc', 'star_rating', 'item_title']\n","template['target_argc'] = 1\n","template['target_argv'] = ['yes_no']\n","template['id'] = \"1-8\"\n","\n","task_subgroup_1[\"1-8\"] = template\n","\n","template = {}\n","'''\n","Input template:\n","Does {{user_desc}} like or dislike {{item_title}}?\n","\n","\n","Target template:\n","{{answer_choices[label]}} (like/dislike) – like (4,5) / dislike (1,2,3)\n","\n","Metrics:\n","Accuracy\n","'''\n","template['source'] = \"Does {} like or dislike {} ?\"\n","template['target'] = \"{}\"\n","template['task'] = \"rating\"\n","template['source_argc'] = 2\n","template['source_argv'] = ['user_desc', 'item_title']\n","template['target_argc'] = 1\n","template['target_argv'] = ['like_dislike']\n","template['id'] = \"1-9\"\n","\n","task_subgroup_1[\"1-9\"] = template\n","\n","template = {}\n","'''\n","Input template:\n","Predict {{user_desc}}’s preference towards {{item_title}} (1 being lowest and 5 being highest)\n","\n","Target template:\n","{{answer_choices[star_rating-1]}}\n","\n","Metrics:\n","Accuracy\n","'''\n","template['source'] = \"Predict {} ’s preference towards {} ( 1 being lowest and 5 being highest )\"\n","template['target'] = \"{}\"\n","template['task'] = \"rating\"\n","template['source_argc'] = 2\n","template['source_argv'] = ['user_desc', 'item_title']\n","template['target_argc'] = 1\n","template['target_argv'] = ['star_rating']\n","template['id'] = \"1-10\"\n","\n","task_subgroup_1[\"1-10\"] = template\n","\n","all_tasks['rating'] = task_subgroup_1\n","\n","# =====================================================\n","# Task Subgroup 2 -- Sequential -- 13 Prompts\n","# =====================================================\n","\n","task_subgroup_2 = {}\n","\n","template = {}\n","\n","'''\n","Input template:\n","Given the following visit history of user {{user_id}}:\n","{{history item list of {{item_id}}}}\n","predict next possible business to be visited by the user?\n","\n","\n","Target template:\n","{{item [item_id]}}\n","\n","\n","Metrics:\n","HR, NDCG, MRR\n","'''\n","\n","template['source'] = \"Given the following visit history of user_{} : \\n {} \\n predict next possible business to be visited by the user ?\"\n","template['target'] = \"{}\"\n","template['task'] = \"sequential\"\n","template['source_argc'] = 2\n","template['source_argv'] = ['user_id', 'visit_history']\n","template['target_argc'] = 1\n","template['target_argv'] = ['item_id']\n","template['id'] = \"2-1\"\n","\n","task_subgroup_2[\"2-1\"] = template\n","\n","template = {}\n","'''\n","Input template:\n","I find the visit history list of user {{user_id}}:\n","{{history item list of {{item_id}}}}\n","I wonder which is the next item to recommend to the user. Can you help me decide?\n","\n","\n","Target template:\n","{{item [item_id]}}\n","\n","\n","Metrics:\n","HR, NDCG, MRR\n","'''\n","template['source'] = \"I find the visit history list of user_{} : \\n {} \\n I wonder what is the next item to recommend to the user . Can you help me decide ?\"\n","template['target'] = \"{}\"\n","template['task'] = \"sequential\"\n","template['source_argc'] = 2\n","template['source_argv'] = ['user_id', 'visit_history']\n","template['target_argc'] = 1\n","template['target_argv'] = ['item_id']\n","template['id'] = \"2-2\"\n","\n","task_subgroup_2[\"2-2\"] = template\n","\n","template = {}\n","'''\n","Input template:\n","Here is the visit history list of user {{user_id}}:\n","{{history item list of {{item_id}}}}\n","try to recommend next item to the user\n","\n","Target template:\n","{{item [item_id]}}\n","\n","\n","Metrics:\n","HR, NDCG, MRR\n","'''\n","template['source'] = \"Here is the visit history list of user_{} : \\n {} \\n try to recommend next item to the user\"\n","template['target'] = \"{}\"\n","template['task'] = \"sequential\"\n","template['source_argc'] = 2\n","template['source_argv'] = ['user_id', 'visit_history']\n","template['target_argc'] = 1\n","template['target_argv'] = ['item_id']\n","template['id'] = \"2-3\"\n","\n","task_subgroup_2[\"2-3\"] = template\n","\n","template = {}\n","\n","'''\n","Input template:\n","Given the following visit history of {{user_desc}}:\n","{{history item list of {{item_id}}}}\n","predict next possible business for the user\n","\n","\n","Target template:\n","{{item [item_id]}}\n","\n","\n","Metrics:\n","HR, NDCG, MRR\n","'''\n","\n","template['source'] = \"Given the following visit history of {} : \\n {} \\n predict next possible business for the user\"\n","template['target'] = \"{}\"\n","template['task'] = \"sequential\"\n","template['source_argc'] = 2\n","template['source_argv'] = ['user_desc', 'visit_history']\n","template['target_argc'] = 1\n","template['target_argv'] = ['item_id']\n","template['id'] = \"2-4\"\n","\n","task_subgroup_2[\"2-4\"] = template\n","\n","template = {}\n","'''\n","Input template:\n","Based on the visit history of {{user_desc}}:\n","{{history item list of {{item_id}}}}\n","Can you decide the next business likely to be visited by the user?\n","\n","\n","Target template:\n","{{item [item_id]}}\n","\n","\n","Metrics:\n","HR, NDCG, MRR\n","'''\n","template[\n","    'source'] = \"Based on the visit history of {} : \\n {} \\n Can you decide the next business likely to be visited by the user ?\"\n","template['target'] = \"{}\"\n","template['task'] = \"sequential\"\n","template['source_argc'] = 2\n","template['source_argv'] = ['user_desc', 'visit_history']\n","template['target_argc'] = 1\n","template['target_argv'] = ['item_id']\n","template['id'] = \"2-5\"\n","\n","task_subgroup_2[\"2-5\"] = template\n","\n","template = {}\n","'''\n","Input template:\n","Here is the visit history of {{user_desc}}:\n","{{history item list of {{item_id}}}}\n","What to recommend next for the user?\n","\n","Target template:\n","{{item [item_id]}}\n","\n","\n","Metrics:\n","HR, NDCG, MRR\n","'''\n","template['source'] = \"Here is the visit history of {} : \\n {} \\n What to recommend next for the user ?\"\n","template['target'] = \"{}\"\n","template['task'] = \"sequential\"\n","template['source_argc'] = 2\n","template['source_argv'] = ['user_desc', 'visit_history']\n","template['target_argc'] = 1\n","template['target_argv'] = ['item_id']\n","template['id'] = \"2-6\"\n","\n","task_subgroup_2[\"2-6\"] = template\n","\n","# Extractive QA\n","template = {}\n","'''\n","Input template:\n","Here is the visit history of user {{user_id}}:\n","{{history item list of {{item_id}}}}\n","Select the next possible business likely to be visited by the user from the following candidates:\n","{{candidate {{item_id}}}}\n","\n","\n","Target template:\n","{{item [item_id]}}\n","\n","\n","Metrics:\n","HR, NDCG, MRR\n","'''\n","template[\n","    'source'] = \"Here is the visit history of user_{} : \\n {} \\n Select the next possible business likely to be visited by the user from the following candidates : \\n {}\"\n","template['target'] = \"{}\"\n","template['task'] = \"sequential\"\n","template['source_argc'] = 3\n","template['source_argv'] = ['user_id', 'visit_history', 'candidates']\n","template['target_argc'] = 1\n","template['target_argv'] = ['item_id']\n","template['id'] = \"2-7\"\n","\n","task_subgroup_2[\"2-7\"] = template\n","\n","template = {}\n","'''\n","Input template:\n","Given the following visit history of {{user_desc}}:\n","{{history item list of {{item_id}}}}\n","What to recommend next for the user? Select one from the following items:\n","{{candidate {{item_id}}}}\n","\n","Target template:\n","{{item [item_id]}}\n","\n","\n","Metrics:\n","HR, NDCG, MRR\n","'''\n","template[\n","    'source'] = \"Given the following visit history of {} : \\n {} \\n What to recommend next for the user? Select one from the following items : \\n {}\"\n","template['target'] = \"{}\"\n","template['task'] = \"sequential\"\n","template['source_argc'] = 3\n","template['source_argv'] = ['user_desc', 'visit_history', 'candidates']\n","template['target_argc'] = 1\n","template['target_argv'] = ['item_id']\n","template['id'] = \"2-8\"\n","\n","task_subgroup_2[\"2-8\"] = template\n","\n","template = {}\n","'''\n","Input template:\n","Based on the visit history of user {{user_id}}:\n","{{history item list of {{item_id}}}}\n","Choose the next possible visited business from the following candidates:\n","{{candidate {{item_id}}}}\n","\n","\n","Target template:\n","{{item [item_id]}}\n","\n","\n","Metrics:\n","HR, NDCG, MRR\n","'''\n","template[\n","    'source'] = \"Based on the visit history of user_{} : \\n {} \\n Choose the next possible visited business from the following candidates : \\n {}\"\n","template['target'] = \"{}\"\n","template['task'] = \"sequential\"\n","template['source_argc'] = 3\n","template['source_argv'] = ['user_id', 'visit_history', 'candidates']\n","template['target_argc'] = 1\n","template['target_argv'] = ['item_id']\n","template['id'] = \"2-9\"\n","\n","task_subgroup_2[\"2-9\"] = template\n","\n","template = {}\n","'''\n","Input template:\n","I find the visit history list of {{user_desc}}:\n","{{history item list of {{item_id}}}}\n","I wonder which is the next item to recommend to the user. Try to select one from the following candidates:\n","{{candidate {{item_id}}}}\n","\n","Target template:\n","{{item [item_id]}}\n","\n","\n","Metrics:\n","HR, NDCG, MRR\n","'''\n","template[\n","    'source'] = \"I find the visit history list of {} : \\n {} \\n I wonder which is the next item to recommend to the user . Try to select one from the following candidates : \\n {}\"\n","template['target'] = \"{}\"\n","template['task'] = \"sequential\"\n","template['source_argc'] = 3\n","template['source_argv'] = ['user_desc', 'visit_history', 'candidates']\n","template['target_argc'] = 1\n","template['target_argv'] = ['item_id']\n","template['id'] = \"2-10\"\n","\n","task_subgroup_2[\"2-10\"] = template\n","\n","template = {}\n","'''\n","Input template:\n","User {{user_id}} has the following visit history:\n","{{history item list of {{item_id}}}}\n","Does the user likely to visit {{item [item_id]}} next?\n","\n","Target template:\n","{{answer_choices[label]}} (yes/no)\n","\n","Metrics:\n","Accuracy\n","'''\n","template['source'] = \"user_{} has the following visit history : \\n {} \\n does the user likely to visit {} next ?\"\n","template['target'] = \"{}\"\n","template['task'] = \"sequential\"\n","template['source_argc'] = 3\n","template['source_argv'] = ['user_id', 'visit_history', 'item_id']\n","template['target_argc'] = 1\n","template['target_argv'] = ['yes_no']\n","template['id'] = \"2-11\"\n","\n","task_subgroup_2[\"2-11\"] = template\n","\n","template = {}\n","'''\n","Input template:\n","According to {{user_desc}}'s visit history list:\n","{{history item list of {{item_id}}}}\n","Predict whether the user will visit {{item [item_id]}} next?\n","\n","Target template:\n","{{answer_choices[label]}} (yes/no)\n","\n","Metrics:\n","Accuracy\n","'''\n","template['source'] = \"According to {} 's visit history list : \\n {} \\n Predict whether the user will visit {} next ?\"\n","template['target'] = \"{}\"\n","template['task'] = \"sequential\"\n","template['source_argc'] = 3\n","template['source_argv'] = ['user_desc', 'visit_history', 'item_id']\n","template['target_argc'] = 1\n","template['target_argv'] = ['yes_no']\n","template['id'] = \"2-12\"\n","\n","task_subgroup_2[\"2-12\"] = template\n","\n","template = {}\n","'''\n","Input template:\n","According to the visit history of {{user_desc}}:\n","{{history item list of {{item_id}}}}\n","Can you recommend the next possible business to the user?\n","\n","Target template:\n","{{item [item_id]}}\n","\n","\n","Metrics:\n","HR, NDCG, MRR\n","'''\n","template[\n","    'source'] = \"According to the visit history of {} : \\n {} \\n Can you recommend the next possible business to the user ?\"\n","template['target'] = \"{}\"\n","template['task'] = \"sequential\"\n","template['source_argc'] = 2\n","template['source_argv'] = ['user_desc', 'visit_history']\n","template['target_argc'] = 1\n","template['target_argv'] = ['item_id']\n","template['id'] = \"2-13\"\n","\n","task_subgroup_2[\"2-13\"] = template\n","\n","all_tasks['sequential'] = task_subgroup_2\n","\n","# ====================================================\n","# Task Subgroup 3 -- Explanation -- 10 Prompts\n","# ====================================================\n","\n","task_subgroup_3 = {}\n","\n","template = {}\n","\n","'''\n","Input template:\n","Generate an explanation for user {{user_id}} about this business: {{item_title}}\n","\n","\n","Target template:\n","{{explanation}}\n","\n","\n","Metrics:\n","BLUE, ROUGE\n","'''\n","\n","template['source'] = \"Generate an explanation for user_{} about this business : {}\"\n","template['target'] = \"{}\"\n","template['task'] = \"explanation\"\n","template['source_argc'] = 2\n","template['source_argv'] = ['user_id', 'item_title']\n","template['target_argc'] = 1\n","template['target_argv'] = ['explanation']\n","template['id'] = \"3-1\"\n","\n","task_subgroup_3[\"3-1\"] = template\n","\n","template = {}\n","'''\n","Input template:\n","Help user {{user_id}} generate a {{star_rating}}-star explanation about this business:\n","{{item_title}}\n","\n","\n","Target template:\n","{{explanation}}\n","\n","\n","Metrics:\n","BLUE, ROUGE\n","'''\n","template['source'] = \"Help user_{} generate a {}-star explanation about this business : \\n {}\"\n","template['target'] = \"{}\"\n","template['task'] = \"explanation\"\n","template['source_argc'] = 3\n","template['source_argv'] = ['user_id', 'star_rating', 'item_title']\n","template['target_argc'] = 1\n","template['target_argv'] = ['explanation']\n","template['id'] = \"3-2\"\n","\n","task_subgroup_3[\"3-2\"] = template\n","\n","template = {}\n","\n","'''\n","Input template:\n","Generate an explanation for {{user_desc}} about this business: {{item_title}}\n","\n","\n","Target template:\n","{{explanation}}\n","\n","\n","Metrics:\n","BLUE, ROUGE\n","'''\n","\n","template['source'] = \"Generate an explanation for {} about this business : {}\"\n","template['target'] = \"{}\"\n","template['task'] = \"explanation\"\n","template['source_argc'] = 2\n","template['source_argv'] = ['user_desc', 'item_title']\n","template['target_argc'] = 1\n","template['target_argv'] = ['explanation']\n","template['id'] = \"3-3\"\n","\n","task_subgroup_3[\"3-3\"] = template\n","\n","template = {}\n","'''\n","Input template:\n","Help {{user_desc}} generate a {{star_rating}}-star explanation for item {{item_id}}\n","\n","\n","Target template:\n","{{explanation}}\n","\n","\n","Metrics:\n","BLUE, ROUGE\n","'''\n","template['source'] = \"Help {} generate a {}-star explanation for item_{}\"\n","template['target'] = \"{}\"\n","template['task'] = \"explanation\"\n","template['source_argc'] = 3\n","template['source_argv'] = ['user_desc', 'star_rating', 'item_id']\n","template['target_argc'] = 1\n","template['target_argv'] = ['explanation']\n","template['id'] = \"3-4\"\n","\n","task_subgroup_3[\"3-4\"] = template\n","\n","template = {}\n","\n","'''\n","Input template:\n","Predict the star rating, then use {{feature}} as feature word to generate user {{user_id}} 's visit explanation for item {{item_id}}\n","\n","\n","Target template:\n","{{star_rating}}, {{explanation}}\n","\n","\n","Metrics:\n","BLUE, ROUGE\n","'''\n","\n","template[\n","    'source'] = \"Predict the star rating , then use {} as feature word to generate user_{} 's visit explanation for item_{}\"\n","template['target'] = \"{} , {}\"\n","template['task'] = \"explanation\"\n","template['source_argc'] = 3\n","template['source_argv'] = ['feature', 'user_id', 'item_id']\n","template['target_argc'] = 2\n","template['target_argv'] = ['star_rating', 'explanation']\n","template['id'] = \"3-5\"\n","\n","task_subgroup_3[\"3-5\"] = template\n","\n","template = {}\n","\n","'''\n","Input template:\n","What score will {{user_desc}} rate item {{item_id}}? Then give an explanation for the rating score. (1 being lowest and 5 being highest)\n","\n","\n","Target template:\n","{{star_rating}}, {{explanation}}\n","\n","\n","Metrics:\n","BLUE, ROUGE\n","'''\n","\n","template[\n","    'source'] = \"What score will {} rate item_{} ? Then give an explanation for the rating score . ( 1 being lowest and 5 being highest )\"\n","template['target'] = \"{} , {}\"\n","template['task'] = \"explanation\"\n","template['source_argc'] = 2\n","template['source_argv'] = ['user_desc', 'item_id']\n","template['target_argc'] = 2\n","template['target_argv'] = ['star_rating', 'explanation']\n","template['id'] = \"3-6\"\n","\n","task_subgroup_3[\"3-6\"] = template\n","\n","template = {}\n","'''\n","Name:\n","Input template:\n","Based on the feature word {{feature}}, generate an explanation for user {{user_id}} about this business: {{item_title}}\n","\n","\n","Target template:\n","{{explanation}}\n","\n","\n","Metrics:\n","BLUE, ROUGE\n","'''\n","\n","template['source'] = \"Based on the feature word {} , generate an explanation for user_{} about this business : {}\"\n","template['target'] = \"{}\"\n","template['task'] = \"explanation\"\n","template['source_argc'] = 3\n","template['source_argv'] = ['feature', 'user_id', 'item_title']\n","template['target_argc'] = 1\n","template['target_argv'] = ['explanation']\n","template['id'] = \"3-7\"\n","\n","task_subgroup_3[\"3-7\"] = template\n","\n","template = {}\n","'''\n","Input template:\n","\n","Given the word {{feature}}, can you help generate an explanation for {{user_desc}} about the business: \\n {{item_title}}\n","\n","\n","Target template:\n","{{explanation}}\n","\n","\n","Metrics:\n","BLUE, ROUGE\n","'''\n","\n","template['source'] = \"Given the word {} , can you help generate an explanation for {} about the business : \\n {}\"\n","template['target'] = \"{}\"\n","template['task'] = \"explanation\"\n","template['source_argc'] = 3\n","template['source_argv'] = ['feature', 'user_desc', 'item_title']\n","template['target_argc'] = 1\n","template['target_argv'] = ['explanation']\n","template['id'] = \"3-8\"\n","\n","task_subgroup_3[\"3-8\"] = template\n","\n","template = {}\n","'''\n","Name:\n","Input template:\n","Using the word {{feature}}, write a {{star_rating}}-star explanation for user {{user_id}} about item {{item_id}}\n","\n","\n","Target template:\n","{{explanation}}\n","\n","\n","Metrics:\n","BLUE, ROUGE\n","'''\n","\n","template['source'] = \"Using the word {} , write a {}-star explanation for user_{} about item_{}\"\n","template['target'] = \"{}\"\n","template['task'] = \"explanation\"\n","template['source_argc'] = 4\n","template['source_argv'] = ['feature', 'star_rating', 'user_id', 'item_id']\n","template['target_argc'] = 1\n","template['target_argv'] = ['explanation']\n","template['id'] = \"3-9\"\n","\n","task_subgroup_3[\"3-9\"] = template\n","\n","template = {}\n","'''\n","Name:\n","Input template:\n","According to the feature word {{feature}}, generate a {{star_rating}}-star explanation for {{user_desc}} about item {{item_id}}\n","\n","\n","Target template:\n","{{explanation}}\n","\n","\n","Metrics:\n","BLUE, ROUGE\n","'''\n","\n","template['source'] = \"According to the feature word {} , generate a {}-star explanation for {} about item_{}\"\n","template['target'] = \"{}\"\n","template['task'] = \"explanation\"\n","template['source_argc'] = 4\n","template['source_argv'] = ['feature', 'star_rating', 'user_desc', 'item_id']\n","template['target_argc'] = 1\n","template['target_argv'] = ['explanation']\n","template['id'] = \"3-10\"\n","\n","task_subgroup_3[\"3-10\"] = template\n","\n","all_tasks['explanation'] = task_subgroup_3\n","\n","# ====================================================\n","# Task Subgroup 4 -- Review -- 3 Prompts\n","# ====================================================\n","\n","task_subgroup_4 = {}\n","\n","template = {}\n","'''\n","Input template:\n","Predict the associated rating score of the review written by user {{user_id}} (1 being lowest and 5 being highest):\n","{{review_body}}\n","\n","\n","Target template:\n","{{star_rating}}\n","\n","\n","Metrics:\n","Accuracy\n","'''\n","template[\n","    'source'] = \"Predict the associated rating score of the review written by user_{} ( 1 being lowest and 5 being highest ) : \\n {}\"\n","template['target'] = \"{}\"\n","template['task'] = \"review\"\n","template['source_argc'] = 2\n","template['source_argv'] = ['user_id', 'review_body']\n","template['target_argc'] = 1\n","template['target_argv'] = ['star_rating']\n","template['id'] = \"4-1\"\n","\n","task_subgroup_4[\"4-1\"] = template\n","\n","template = {}\n","'''\n","Input template:\n","Given the following review written by user {{user_id}}:\n","{{review_body}}\n","Can you predict the associated star rating (1 being lowest and 5 being highest)?\n","\n","\n","Target template:\n","{{star_rating}}\n","\n","\n","Metrics:\n","Accuracy\n","'''\n","template[\n","    'source'] = \"Given the following review written by user_{} : \\n {} \\n Can you predict the associated star rating ? ( 1 being lowest and 5 being highest )\"\n","template['target'] = \"{}\"\n","template['task'] = \"review\"\n","template['source_argc'] = 2\n","template['source_argv'] = ['user_id', 'review_body']\n","template['target_argc'] = 1\n","template['target_argv'] = ['star_rating']\n","template['id'] = \"4-2\"\n","\n","task_subgroup_4[\"4-2\"] = template\n","\n","template = {}\n","'''\n","Input template:\n","According to the following review written by {{user_desc}}:\n","{{review_body}}\n","Predict the associated star rating (1 being lowest and 5 being highest)\n","\n","\n","Target template:\n","{{star_rating}}\n","\n","\n","Metrics:\n","Accuracy\n","'''\n","template[\n","    'source'] = \"According to the following review written by {} : \\n {} \\n Predict the associated star rating ( 1 being lowest and 5 being highest )\"\n","template['target'] = \"{}\"\n","template['task'] = \"review\"\n","template['source_argc'] = 2\n","template['source_argv'] = ['user_desc', 'review_body']\n","template['target_argc'] = 1\n","template['target_argv'] = ['star_rating']\n","template['id'] = \"4-3\"\n","\n","task_subgroup_4[\"4-3\"] = template\n","\n","all_tasks['review'] = task_subgroup_4\n","\n","# =====================================================\n","# Task Subgroup 5 -- Traditional -- 8 Prompts\n","# =====================================================\n","\n","task_subgroup_5 = {}\n","\n","## Interaction Prediction (Binary Classification) - 4 prompts\n","\n","template = {}\n","\n","'''\n","Input template:\n","Will user {{user_id}} likely to interact with item {{item_id}}?\n","\n","\n","Target template:\n","{{answer_choices[label]}} (yes/no)\n","\n","\n","Metrics:\n","Accuracy (HR, NDCG, MRRs)\n","'''\n","\n","template['source'] = \"Will user_{} likely to interact with item_{} ?\"\n","template['target'] = \"{}\"\n","template['task'] = \"traditional\"\n","template['source_argc'] = 2\n","template['source_argv'] = ['user_id', 'item_id']\n","template['target_argc'] = 1\n","template['target_argv'] = ['yes_no']\n","template['id'] = \"5-1\"\n","\n","task_subgroup_5[\"5-1\"] = template\n","\n","template = {}\n","\n","'''\n","Input template:\n","Shall we recommend item {{item_id}} to {{user_desc}}?\n","\n","\n","Target template:\n","{{answer_choices[label]}} (yes/no)\n","\n","\n","Metrics:\n","Accuracy (HR, NDCG, MRRs)\n","'''\n","\n","template['source'] = \"Shall we recommend item_{} to {} ?\"\n","template['target'] = \"{}\"\n","template['task'] = \"traditional\"\n","template['source_argc'] = 2\n","template['source_argv'] = ['item_id', 'user_desc']\n","template['target_argc'] = 1\n","template['target_argv'] = ['yes_no']\n","template['id'] = \"5-2\"\n","\n","task_subgroup_5[\"5-2\"] = template\n","\n","template = {}\n","\n","'''\n","Input template:\n","For {{user_desc}}, do you think it is good to recommend {{item_title}}?\n","\n","\n","Target template:\n","{{answer_choices[label]}} (yes/no)\n","\n","\n","Metrics:\n","Accuracy (HR, NDCG, MRRs)\n","'''\n","\n","template['source'] = \"For {}, do you think it is good to recommend {} ?\"\n","template['target'] = \"{}\"\n","template['task'] = \"traditional\"\n","template['source_argc'] = 2\n","template['source_argv'] = ['user_desc', 'item_title']\n","template['target_argc'] = 1\n","template['target_argv'] = ['yes_no']\n","template['id'] = \"5-3\"\n","\n","task_subgroup_5[\"5-3\"] = template\n","\n","template = {}\n","\n","'''\n","Input template:\n","I would like to recommend some items for user {{user_id}}. Is the following item a good choice?\n","{{item_title}}\n","\n","\n","Target template:\n","{{answer_choices[label]}} (yes/no)\n","\n","\n","Metrics:\n","Accuracy (HR, NDCG, MRRs)\n","'''\n","\n","template['source'] = \"I would like to recommend some items for user_{} . Is the following item a good choice ? \\n {}\"\n","template['target'] = \"{}\"\n","template['task'] = \"traditional\"\n","template['source_argc'] = 2\n","template['source_argv'] = ['user_id', 'item_title']\n","template['target_argc'] = 1\n","template['target_argv'] = ['yes_no']\n","template['id'] = \"5-4\"\n","\n","task_subgroup_5[\"5-4\"] = template\n","\n","## Extractive QA - 4 prompts\n","template = {}\n","\n","'''\n","Input template:\n","Which item of the following to recommend for {{user_desc}}?\n","{{candidate {{item_id}}}}\n","\n","\n","Target template:\n","{{groundtruth {{item ids}}}}\n","\n","\n","Metrics:\n","HR, NDCG, MRR\n","'''\n","\n","template['source'] = \"Which item of the following to recommend for {} ? \\n {}\"\n","template['target'] = \"{}\"\n","template['task'] = \"traditional\"\n","template['source_argc'] = 2\n","template['source_argv'] = ['user_desc', 'candidates']\n","template['target_argc'] = 1\n","template['target_argv'] = ['groundtruth_item_ids']\n","template['id'] = \"5-5\"\n","\n","task_subgroup_5[\"5-5\"] = template\n","\n","template = {}\n","\n","'''\n","Input template:\n","Choose the best item from the candidates to recommend for {{user_desc}}?\n","{{candidate {{item_id}}}}\n","\n","\n","Target template:\n","{{groundtruth {{item ids}}}}\n","\n","\n","Metrics:\n","HR, NDCG, MRR\n","'''\n","\n","template['source'] = \"Choose the best item from the candidates to recommend for {} ? \\n {}\"\n","template['target'] = \"{}\"\n","template['task'] = \"traditional\"\n","template['source_argc'] = 2\n","template['source_argv'] = ['user_desc', 'candidates']\n","template['target_argc'] = 1\n","template['target_argv'] = ['groundtruth_item_ids']\n","template['id'] = \"5-6\"\n","\n","task_subgroup_5[\"5-6\"] = template\n","\n","template = {}\n","\n","'''\n","Input template:\n","Pick the most suitable item from the following list and recommend to user {{user_id}}:\n","{{candidate {{item_id}}}}\n","\n","\n","Target template:\n","{{groundtruth {{item ids}}}}\n","\n","\n","Metrics:\n","HR, NDCG, MRR\n","'''\n","\n","template['source'] = \"Pick the most suitable item from the following list and recommend to user_{} : \\n {}\"\n","template['target'] = \"{}\"\n","template['task'] = \"traditional\"\n","template['source_argc'] = 2\n","template['source_argv'] = ['user_id', 'candidates']\n","template['target_argc'] = 1\n","template['target_argv'] = ['groundtruth_item_ids']\n","template['id'] = \"5-7\"\n","\n","task_subgroup_5[\"5-7\"] = template\n","\n","template = {}\n","\n","'''\n","Input template:\n","We want to make recommendation for user {{user_id}}. Select the best item from these candidates:\n","{{candidate {{item_id}}}}\n","\n","\n","Target template:\n","{{groundtruth {{item ids}}}}\n","\n","\n","Metrics:\n","HR, NDCG, MRR\n","'''\n","\n","template['source'] = \"We want to make recommendation for user_{} .  Select the best item from these candidates : \\n {}\"\n","template['target'] = \"{}\"\n","template['task'] = \"traditional\"\n","template['source_argc'] = 2\n","template['source_argv'] = ['user_id', 'candidates']\n","template['target_argc'] = 1\n","template['target_argv'] = ['groundtruth_item_ids']\n","template['id'] = \"5-8\"\n","\n","task_subgroup_5[\"5-8\"] = template\n","\n","all_tasks['traditional'] = task_subgroup_5\n","\n","task_templates = all_tasks"]},{"cell_type":"markdown","metadata":{"id":"GP58xp2LcglD"},"source":["#### Utils"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_-h34fRocijG"},"outputs":[],"source":["class LossMeter(object):\n","    def __init__(self, maxlen=100):\n","        \"\"\"Computes and stores the running average\"\"\"\n","        self.vals = collections.deque([], maxlen=maxlen)\n","\n","    def __len__(self):\n","        return len(self.vals)\n","\n","    def update(self, new_val):\n","        self.vals.append(new_val)\n","\n","    @property\n","    def val(self):\n","        return sum(self.vals) / len(self.vals)\n","\n","    def __repr__(self):\n","        return str(self.val)\n","\n","\n","def count_parameters(model):\n","    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n","\n","\n","def load_state_dict(state_dict_path, loc='cpu'):\n","    state_dict = torch.load(state_dict_path, map_location=loc)\n","    # Change Multi GPU to single GPU\n","    original_keys = list(state_dict.keys())\n","    for key in original_keys:\n","        if key.startswith(\"module.\"):\n","            new_key = key[len(\"module.\"):]\n","            state_dict[new_key] = state_dict.pop(key)\n","    return state_dict\n","\n","\n","def set_global_logging_level(level=logging.ERROR, prefices=[\"\"]):\n","    \"\"\"\n","    Override logging levels of different modules based on their name as a prefix.\n","    It needs to be invoked after the modules have been loaded so that their loggers have been initialized.\n","\n","    Args:\n","        - level: desired level. e.g. logging.INFO. Optional. Default is logging.ERROR\n","        - prefices: list of one or more str prefices to match (e.g. [\"transformers\", \"torch\"]). Optional.\n","          Default is `[\"\"]` to match all active loggers.\n","          The match is a case-sensitive `module_name.startswith(prefix)`\n","    \"\"\"\n","    prefix_re = re.compile(fr'^(?:{ \"|\".join(prefices) })')\n","    for name in logging.root.manager.loggerDict:\n","        if re.match(prefix_re, name):\n","            logging.getLogger(name).setLevel(level)"]},{"cell_type":"markdown","metadata":{"id":"XopD5BB3Zra2"},"source":["#### Tokenizer"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"F4lWYsz8Z1G0"},"outputs":[],"source":["class CustomTokenizer(T5Tokenizer):\n","\n","    def __init__(self, vocab_file, eos_token=\"</s>\", unk_token=\"<unk>\", pad_token=\"<pad>\", extra_ids=100, user_extra_ids=0, item_extra_ids=0, **kwargs):\n","        self.vocab_file = vocab_file\n","        self._extra_ids = extra_ids\n","        self._user_extra_ids = user_extra_ids\n","        self._item_extra_ids = item_extra_ids\n","        self.additional_special_tokens = [f\"<extra_id_{i}>\" for i in range(extra_ids)]\n","        if user_extra_ids>0:\n","            self.additional_special_tokens.extend([f\"<user_id_{i}>\" for i in range(user_extra_ids)])\n","        if item_extra_ids>0:\n","            self.additional_special_tokens.extend([f\"<item_id_{i}>\" for i in range(item_extra_ids)])\n","\n","        super().__init__(vocab_file, eos_token=eos_token, unk_token=unk_token, pad_token=pad_token, **kwargs)\n","        self.add_special_tokens({\"additional_special_tokens\": self.additional_special_tokens})\n","        self.sp_model = spm.SentencePieceProcessor()\n","        self.sp_model.Load(vocab_file)\n","\n","    @property\n","    def vocab_size(self):\n","        return self.sp_model.get_piece_size() + self._extra_ids + self._user_extra_ids + self._item_extra_ids\n","\n","    def get_vocab(self):\n","        vocab = {self.convert_ids_to_tokens(i): i for i in range(self.vocab_size)}\n","        vocab.update(self.added_tokens_encoder)\n","        return vocab\n","\n","    def _convert_token_to_id(self, token):\n","        if token.startswith(\"<extra_id_\"):\n","            match = re.match(r\"<extra_id_(\\d+)>\", token)\n","            num = int(match.group(1))\n","            return self.vocab_size - num - 1 - self._user_extra_ids - self._item_extra_ids\n","        elif \"<user_id_\" in token:\n","            match = re.match(r\"<user_id_(\\d+)>\", token)\n","            num = int(match.group(1))\n","            return self.vocab_size - num - 1 - self._item_extra_ids\n","        elif \"<item_id_\" in token:\n","            match = re.match(r\"<item_id_(\\d+)>\", token)\n","            num = int(match.group(1))\n","            return self.vocab_size - num - 1\n","        return self.sp_model.piece_to_id(token)\n","\n","\n","    def _convert_id_to_token(self, index):\n","        if index < self.sp_model.get_piece_size():\n","            token = self.sp_model.IdToPiece(index)\n","        else:\n","            if index > self.sp_model.get_piece_size() + self._extra_ids + self._user_extra_ids - 1:\n","                token = \"<item_id_{}>\".format(self.vocab_size - 1 - index)\n","            elif index > self.sp_model.get_piece_size() + self._extra_ids - 1:\n","                token = \"<user_id_{}>\".format(self.vocab_size - self._item_extra_ids - 1 - index)\n","            else:\n","                token = \"<extra_id_{}>\".format(self.vocab_size - self._user_extra_ids - self._item_extra_ids - 1 - index)\n","        return token"]},{"cell_type":"markdown","metadata":{"id":"wWBwVYdEZ66R"},"source":["#### Get Data"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"it6v-vAHZ-5_"},"outputs":[],"source":["def load_json(file_path):\n","    with open(file_path, \"r\") as f:\n","        return json.load(f)\n","def load_pickle(filename):\n","    with open(filename, \"rb\") as f:\n","        return pickle.load(f)\n","def ReadLineFromFile(path):\n","    lines = []\n","    with open(path, 'r') as fd:\n","        for line in fd:\n","            lines.append(line.rstrip('\\n'))\n","    return lines\n","def parse(path):\n","    g = gzip.open(path, 'r')\n","    for l in g:\n","        yield eval(l)\n","\n","\n","class P5YelpDataset(Dataset):\n","    def __init__(self, all_tasks, task_list, tokenizer, args, sample_numbers, mode='train', rating_augment=False, sample_type='random'):\n","        self.all_tasks = all_tasks\n","        self.task_list = task_list\n","        self.tokenizer = tokenizer\n","        self.args = args\n","        self.sample_numbers = sample_numbers\n","        self.rating_augment = rating_augment\n","        self.sample_type = sample_type\n","        self.mode = mode\n","        self.data_source_folder = \"drive/MyDrive/P5 Recommender/data/\"\n","\n","        self.review_data = load_pickle(self.data_source_folder + \"review_splits.pkl\")[self.mode]\n","        self.exp_data = load_pickle(self.data_source_folder + \"exp_splits.pkl\")[self.mode]\n","        if self.rating_augment:\n","            self.rating_data = load_pickle(self.data_source_folder + \"rating_splits_augmented.pkl\")[self.mode]\n","        else:\n","            self.rating_data = self.review_data\n","\n","        # what all restaurants the user has visited,  user_id1 business_id1 business_id2 business_id3 ....\n","        self.sequential_data = ReadLineFromFile(self.data_source_folder + \"sequential_data.txt\")\n","        item_count = defaultdict(int)\n","        user_items = defaultdict()\n","        for line in self.sequential_data:\n","            user, items = line.strip().split(' ', 1)\n","            items = items.split(' ')\n","            items = [int(item) for item in items]\n","            user_items[user] = items\n","            for item in items:\n","                item_count[item] += 1\n","        self.all_item = list(item_count.keys())\n","        count = list(item_count.values())\n","        sum_value = np.sum([x for x in count])\n","        # probability of picking one item\n","        self.probability = [value / sum_value for value in count]\n","        self.user_items = user_items\n","\n","        if self.mode == 'test':\n","            self.negative_samples = ReadLineFromFile(self.data_source_folder + \"negative_samples.txt\")\n","\n","        # this json contains just the mappings, user2id, id2user, item2id, id2item\n","        # total users-30431,  items-20033\n","        datamaps = load_json(self.data_source_folder + \"datamaps.json\")\n","        self.user2id = datamaps['user2id']\n","        self.item2id = datamaps['item2id']\n","        self.user_list = list(datamaps['user2id'].keys())\n","        self.item_list = list(datamaps['item2id'].keys())\n","        self.id2item = datamaps['id2item']\n","\n","        # we have 30431 users, user_id: user_name\n","        self.user_id2name = load_pickle(self.data_source_folder + \"user_id2name.pkl\")\n","        # we have 20033 restaurants, for each restaurant name, demographic details, attributes such as what ambience, parking, alcohol etc are present\n","        self.meta_data = load_pickle(self.data_source_folder + \"meta_data.pkl\")\n","        # for all the 30431 users, we have data like user_id, name, total reviews, friends, when started using yelp, different compliments\n","        self.user_data = load_pickle(self.data_source_folder + \"user_data.pkl\")\n","\n","        # just a mapping of restaurant / business_id and index\n","        self.meta_dict = {}\n","        for i, meta_item in enumerate(self.meta_data):\n","            self.meta_dict[meta_item['business_id']] = i\n","        print(\"Total number of businesses: stored in self.meta_dict\", len(self.meta_dict))\n","        self.user_meta_dict = {}\n","        for j, user_meta_item in enumerate(self.user_data):\n","            self.user_meta_dict[user_meta_item['user_id']] = j\n","        print(\"Total umber of users: stored in self.user_meta_dict\", len(self.user_meta_dict))\n","\n","        print('compute_datum_info')\n","        self.total_length = 0\n","        self.datum_info = []\n","        self.compute_datum_info()\n","        print(\"Init call finished\")\n","\n","    def compute_datum_info(self):\n","        curr = 0\n","        for key in list(self.task_list.keys()):\n","            if key == 'rating':  #\n","                self.total_length += len(self.rating_data) * self.sample_numbers[key]\n","                for i in range(self.total_length - curr):\n","                    self.datum_info.append((i + curr, key, i // self.sample_numbers[key]))\n","                curr = self.total_length\n","            elif key == 'sequential':\n","                if sum([0 < int(ind.split('-')[1]) <= 6 or int(ind.split('-')[1]) == 13 for ind in self.task_list[key]]):\n","                    self.total_length += len(self.sequential_data) * self.sample_numbers[key][0]\n","                    for i in range(self.total_length - curr):\n","                        self.datum_info.append((i + curr, key, i // self.sample_numbers[key][0]))\n","                    curr = self.total_length\n","                if sum([6 < int(ind.split('-')[1]) <= 10 for ind in self.task_list[key]]):\n","                    self.total_length += len(self.sequential_data) * self.sample_numbers[key][1]\n","                    for i in range(self.total_length - curr):\n","                        self.datum_info.append((i + curr, key, i // self.sample_numbers[key][1]))\n","                    curr = self.total_length\n","                if sum([10 < int(ind.split('-')[1]) <= 12 for ind in self.task_list[key]]):\n","                    self.total_length += len(self.sequential_data) * self.sample_numbers[key][2]\n","                    for i in range(self.total_length - curr):\n","                        self.datum_info.append((i + curr, key, i // self.sample_numbers[key][2]))\n","                    curr = self.total_length\n","            elif key == 'explanation':\n","                self.total_length += len(self.exp_data) * self.sample_numbers[key]\n","                for i in range(self.total_length - curr):\n","                    self.datum_info.append((i + curr, key, i // self.sample_numbers[key]))\n","                curr = self.total_length\n","            elif key == 'review':\n","                self.total_length += len(self.review_data) * self.sample_numbers[key]\n","                for i in range(self.total_length - curr):\n","                    self.datum_info.append((i + curr, key, i // self.sample_numbers[key]))\n","                curr = self.total_length\n","            elif key == 'traditional':\n","                if sum([0 < int(ind.split('-')[1]) <= 4 for ind in self.task_list[key]]):\n","                    self.total_length += len(self.user2id) * self.sample_numbers[key][0]\n","                    for i in range(self.total_length - curr):\n","                        self.datum_info.append((i + curr, key, i // self.sample_numbers[key][0]))\n","                    curr = self.total_length\n","                if sum([4 < int(ind.split('-')[1]) <= 8 for ind in self.task_list[key]]):\n","                    self.total_length += len(self.user2id) * self.sample_numbers[key][1]\n","                    for i in range(self.total_length - curr):\n","                        self.datum_info.append((i + curr, key, i // self.sample_numbers[key][1]))\n","                    curr = self.total_length\n","            else:\n","                raise NotImplementedError\n","\n","    def gaussian_sampling(self, datum):\n","        if self.mode == 'train':\n","            if int(datum['overall']) == 1:\n","                sampled_rating = round(torch.normal(mean=torch.tensor((1.0+1.4)/2), std=torch.tensor((1.4-1.0)/4)).item(), 1)\n","            elif int(datum['overall']) == 2:\n","                sampled_rating = round(torch.normal(mean=torch.tensor((1.5+2.4)/2), std=torch.tensor((2.4-1.5)/4)).item(), 1)\n","            elif int(datum['overall']) == 3:\n","                sampled_rating = round(torch.normal(mean=torch.tensor((2.5+3.4)/2), std=torch.tensor((3.4-2.5)/4)).item(), 1)\n","            elif int(datum['overall']) == 4:\n","                sampled_rating = round(torch.normal(mean=torch.tensor((3.5+4.4)/2), std=torch.tensor((4.4-3.5)/4)).item(), 1)\n","            else:\n","                sampled_rating = round(torch.normal(mean=torch.tensor((4.5+5.0)/2), std=torch.tensor((5.0-4.5)/4)).item(), 1)\n","            if sampled_rating > 5.0:\n","                sampled_rating = 5.0\n","            if sampled_rating < 1.0:\n","                sampled_rating = 1.0\n","            return str(sampled_rating)\n","        else:\n","            return int(datum['overall'])\n","\n","    def collate_fn(self, batch):\n","        batch_entry = {}\n","        B = len(batch)\n","        args = self.args\n","        S_W_L = max(entry['input_length'] for entry in batch)\n","        T_W_L = max(entry['target_length'] for entry in batch)\n","\n","        input_ids = torch.ones(B, S_W_L, dtype=torch.long) * self.tokenizer.pad_token_id\n","        whole_word_ids = torch.ones(B, S_W_L, dtype=torch.long) * self.tokenizer.pad_token_id\n","        target_ids = torch.ones(B, T_W_L, dtype=torch.long) * self.tokenizer.pad_token_id\n","        loss_weights = torch.ones(B, dtype=torch.float)\n","\n","        tasks = []\n","        source_text = []\n","        tokenized_text = []\n","        target_text = []\n","\n","        for i, entry in enumerate(batch):\n","            input_ids[i, :entry['input_length']] = entry['input_ids']\n","            whole_word_ids[i, :entry['input_length']] = entry['whole_word_ids']\n","            target_ids[i, :entry['target_length']] = entry['target_ids']\n","\n","            if 'task' in entry:\n","                tasks.append(entry['task'])\n","\n","            if 'source_text' in entry:\n","                source_text.append(entry['source_text'])\n","\n","            if 'tokenized_text' in entry:\n","                tokenized_text.append(entry['tokenized_text'])\n","\n","            if 'target_text' in entry:\n","                target_text.append(entry['target_text'])\n","\n","            if 'loss_weight' in entry:\n","                loss_weights[i] = entry['loss_weight']\n","\n","        word_mask = target_ids != self.tokenizer.pad_token_id\n","        target_ids[~word_mask] = -100\n","        batch_entry['task'] = tasks\n","        batch_entry['source_text'] = source_text\n","        batch_entry['target_text'] = target_text\n","        batch_entry['input_ids'] = input_ids\n","        batch_entry['whole_word_ids'] = whole_word_ids\n","        batch_entry['target_ids'] = target_ids\n","        batch_entry['loss_weights'] = loss_weights\n","\n","        return batch_entry\n","\n","    def calculate_whole_word_ids(self, tokenized_text, input_ids):\n","        whole_word_ids = []\n","        curr = 0\n","        for i in range(len(tokenized_text)):\n","            if tokenized_text[i].startswith('▁'):\n","                curr += 1\n","                whole_word_ids.append(curr)\n","            else:\n","                whole_word_ids.append(curr)\n","        last_item = whole_word_ids[len(input_ids) - 2]\n","        return whole_word_ids[:len(input_ids) - 1] + [0] # [0] for </s>\n","\n","    def __len__(self):\n","        return self.total_length\n","\n","    def __getitem__(self, idx):\n","\n","        out_dict = {}\n","        out_dict['args'] = self.args\n","\n","        loss_weight = 1.0\n","\n","        datum_info_idx = self.datum_info[idx]\n","        task_name = datum_info_idx[1]\n","        datum_idx = datum_info_idx[2]\n","\n","        if task_name == 'rating':\n","            rating_datum = self.rating_data[datum_idx]\n","            task_candidates = self.task_list[task_name]\n","            task_idx = random.randint(0, len(task_candidates) - 1)  # random choose the task index for task_candidates\n","            task_template = self.all_tasks['rating'][task_candidates[task_idx]]\n","            assert task_template['task'] == 'rating'\n","\n","            if task_template['id'] == '1-1':\n","                source_text = task_template['source'].format(self.user2id[rating_datum['reviewerID']],\n","                                                             self.item2id[rating_datum['asin']])\n","                target_text = task_template['target'].format(self.gaussian_sampling(rating_datum))\n","            elif task_template['id'] == '1-2':\n","                if 'name' in self.meta_data[self.meta_dict[rating_datum['asin']]]:\n","                    title = self.meta_data[self.meta_dict[rating_datum['asin']]]['name']\n","                else:\n","                    title = 'unknown name'\n","                source_text = task_template['source'].format(self.user2id[rating_datum['reviewerID']], title)\n","                target_text = task_template['target'].format(self.gaussian_sampling(rating_datum))\n","            elif task_template['id'] == '1-3':\n","                rand_prob = random.random()\n","                if rand_prob > 0.5:\n","                    source_text = task_template['source'].format(self.user2id[rating_datum['reviewerID']],\n","                                                                 self.item2id[rating_datum['asin']],\n","                                                                 int(rating_datum['overall']))\n","                    target_text = task_template['target'].format('yes')\n","                else:\n","                    overall_candidates = [_ for _ in range(0 + 1, 5 + 1) if _ != int(rating_datum['overall'])]\n","                    overall_idx = random.randint(0, len(overall_candidates) - 1)  # random choose the overall index for overall_candidates\n","                    source_text = task_template['source'].format(self.user2id[rating_datum['reviewerID']],\n","                                                                 self.item2id[rating_datum['asin']],\n","                                                                 overall_candidates[overall_idx])\n","                    target_text = task_template['target'].format('no')\n","            elif task_template['id'] == '1-4':\n","                source_text = task_template['source'].format(self.user2id[rating_datum['reviewerID']],\n","                                                             self.item2id[rating_datum['asin']])\n","                if int(rating_datum['overall']) >= 4:\n","                    target_text = task_template['target'].format('like')\n","                else:\n","                    target_text = task_template['target'].format('dislike')\n","            elif task_template['id'] == '1-5':\n","                if 'name' in self.meta_data[self.meta_dict[rating_datum['asin']]]:\n","                    title = self.meta_data[self.meta_dict[rating_datum['asin']]]['name']\n","                else:\n","                    title = 'unknown name'\n","                source_text = task_template['source'].format(self.user2id[rating_datum['reviewerID']],\n","                                                             self.item2id[rating_datum['asin']], title)\n","                target_text = task_template['target'].format(self.gaussian_sampling(rating_datum))\n","            elif task_template['id'] == '1-6':\n","                if 'name' in self.user_data[self.user_meta_dict[rating_datum['reviewerID']]]:\n","                    user_desc = self.user_data[self.user_meta_dict[rating_datum['reviewerID']]]['name']\n","                else:\n","                    user_desc = rating_datum['reviewerID']\n","                source_text = task_template['source'].format(user_desc, self.item2id[rating_datum['asin']])\n","                target_text = task_template['target'].format(self.gaussian_sampling(rating_datum))\n","            elif task_template['id'] == '1-7':\n","                if 'name' in self.user_data[self.user_meta_dict[rating_datum['reviewerID']]]:\n","                    user_desc = self.user_data[self.user_meta_dict[rating_datum['reviewerID']]]['name']\n","                else:\n","                    user_desc = rating_datum['reviewerID']\n","                if 'name' in self.meta_data[self.meta_dict[rating_datum['asin']]]:\n","                    title = self.meta_data[self.meta_dict[rating_datum['asin']]]['name']\n","                else:\n","                    title = 'unknown name'\n","                source_text = task_template['source'].format(user_desc, title)\n","                target_text = task_template['target'].format(self.gaussian_sampling(rating_datum))\n","            elif task_template['id'] == '1-8':\n","                rand_prob = random.random()\n","                if 'name' in self.user_data[self.user_meta_dict[rating_datum['reviewerID']]]:\n","                    user_desc = self.user_data[self.user_meta_dict[rating_datum['reviewerID']]]['name']\n","                else:\n","                    user_desc = rating_datum['reviewerID']\n","                if 'name' in self.meta_data[self.meta_dict[rating_datum['asin']]]:\n","                    title = self.meta_data[self.meta_dict[rating_datum['asin']]]['name']\n","                else:\n","                    title = 'unknown name'\n","                if rand_prob > 0.5:\n","                    source_text = task_template['source'].format(user_desc, int(rating_datum['overall']), title)\n","                    target_text = task_template['target'].format('yes')\n","                else:\n","                    overall_candidates = [_ for _ in range(0 + 1, 5 + 1) if _ != int(rating_datum['overall'])]\n","                    overall_idx = random.randint(0,\n","                                                 len(overall_candidates) - 1)  # random choose the overall index for overall_candidates\n","                    source_text = task_template['source'].format(user_desc, overall_candidates[overall_idx], title)\n","                    target_text = task_template['target'].format('no')\n","            elif task_template['id'] == '1-9':\n","                if 'name' in self.user_data[self.user_meta_dict[rating_datum['reviewerID']]]:\n","                    user_desc = self.user_data[self.user_meta_dict[rating_datum['reviewerID']]]['name']\n","                else:\n","                    user_desc = rating_datum['reviewerID']\n","                if 'name' in self.meta_data[self.meta_dict[rating_datum['asin']]]:\n","                    title = self.meta_data[self.meta_dict[rating_datum['asin']]]['name']\n","                else:\n","                    title = 'unknown name'\n","                source_text = task_template['source'].format(user_desc, title)\n","                if int(rating_datum['overall']) >= 4:\n","                    target_text = task_template['target'].format('like')\n","                else:\n","                    target_text = task_template['target'].format('dislike')\n","            elif task_template['id'] == '1-10':\n","                if 'name' in self.user_data[self.user_meta_dict[rating_datum['reviewerID']]]:\n","                    user_desc = self.user_data[self.user_meta_dict[rating_datum['reviewerID']]]['name']\n","                else:\n","                    user_desc = rating_datum['reviewerID']\n","                if 'name' in self.meta_data[self.meta_dict[rating_datum['asin']]]:\n","                    title = self.meta_data[self.meta_dict[rating_datum['asin']]]['name']\n","                else:\n","                    title = 'unknown name'\n","                source_text = task_template['source'].format(user_desc, title)\n","                target_text = task_template['target'].format(self.gaussian_sampling(rating_datum))\n","            else:\n","                raise NotImplementedError\n","\n","        elif task_name == 'sequential':\n","            sequential_datum = self.sequential_data[datum_idx]\n","            sequence = sequential_datum.split()\n","            user_id = sequence[0]\n","            user_desc = self.user_id2name[user_id]\n","            history_limit = 20\n","            if self.mode == 'train':\n","                end_candidates = [_ for _ in range(max(2, len(sequence) - 6), len(sequence) - 3)]\n","                end_index = random.randint(0, len(end_candidates) - 1)\n","                end_pos = end_candidates[end_index]\n","                start_candidates = [_ for _ in range(1, min(4, end_pos))]\n","                start_index = random.randint(0, len(start_candidates) - 1)\n","                start_pos = start_candidates[start_index]\n","                purchase_history = sequence[start_pos:end_pos + 1]\n","                target_item = sequence[end_pos + 1]\n","            elif self.mode == 'val':\n","                purchase_history = sequence[1:-2]\n","                target_item = sequence[-2]\n","            elif self.mode == 'test':\n","                purchase_history = sequence[1:-1]\n","                target_item = sequence[-1]\n","            else:\n","                raise NotImplementedError\n","            if len(purchase_history) > history_limit:\n","                purchase_history = purchase_history[-history_limit:]\n","\n","            task_candidates = self.task_list[task_name]\n","            task_idx = random.randint(0, len(task_candidates) - 1)  # random choose the task index for task_candidates\n","            task_template = self.all_tasks['sequential'][task_candidates[task_idx]]\n","            assert task_template['task'] == 'sequential'\n","\n","            if task_template['id'] == '2-1':\n","                rand_prob = random.random()\n","                if rand_prob > 0.5:\n","                    source_text = task_template['source'].format(user_id, ' , '.join(purchase_history))\n","                else:\n","                    source_text = task_template['source'].format(user_id, ' -> '.join(purchase_history))\n","                target_text = task_template['target'].format(target_item)\n","            elif task_template['id'] == '2-2':\n","                rand_prob = random.random()\n","                if rand_prob > 0.5:\n","                    source_text = task_template['source'].format(user_id, ' , '.join(purchase_history))\n","                else:\n","                    source_text = task_template['source'].format(user_id, ' -> '.join(purchase_history))\n","                target_text = task_template['target'].format(target_item)\n","            elif task_template['id'] == '2-3':\n","                rand_prob = random.random()\n","                if rand_prob > 0.5:\n","                    source_text = task_template['source'].format(user_id, ' , '.join(purchase_history))\n","                else:\n","                    source_text = task_template['source'].format(user_id, ' -> '.join(purchase_history))\n","                target_text = task_template['target'].format(target_item)\n","            elif task_template['id'] == '2-4':\n","                rand_prob = random.random()\n","                if rand_prob > 0.5:\n","                    source_text = task_template['source'].format(user_desc, ' , '.join(purchase_history))\n","                else:\n","                    source_text = task_template['source'].format(user_desc, ' -> '.join(purchase_history))\n","                target_text = task_template['target'].format(target_item)\n","            elif task_template['id'] == '2-5':\n","                rand_prob = random.random()\n","                if rand_prob > 0.5:\n","                    source_text = task_template['source'].format(user_desc, ' , '.join(purchase_history))\n","                else:\n","                    source_text = task_template['source'].format(user_desc, ' -> '.join(purchase_history))\n","                target_text = task_template['target'].format(target_item)\n","            elif task_template['id'] == '2-6':\n","                rand_prob = random.random()\n","                if rand_prob > 0.5:\n","                    source_text = task_template['source'].format(user_desc, ' , '.join(purchase_history))\n","                else:\n","                    source_text = task_template['source'].format(user_desc, ' -> '.join(purchase_history))\n","                target_text = task_template['target'].format(target_item)\n","            elif task_template['id'] == '2-7' or task_template['id'] == '2-9':\n","                if self.mode in ['train', 'val']:\n","                    user_seq = self.user_items[user_id]\n","                    candidate_samples = []\n","                    candidate_num = random.randint(79, 99)\n","                    while len(candidate_samples) < candidate_num:\n","                        if self.sample_type == 'random':\n","                            sample_ids = np.random.choice(self.all_item, candidate_num, replace=False)\n","                        else:\n","                            sample_ids = np.random.choice(self.all_item, candidate_num, replace=False,\n","                                                          p=self.probability)\n","                        sample_ids = [str(item) for item in sample_ids if item not in user_seq and item not in candidate_samples]\n","                        candidate_samples.extend(sample_ids)\n","                    candidate_samples = candidate_samples[:candidate_num]\n","                elif self.mode == 'test':\n","                    assert user_id == self.negative_samples[int(user_id) - 1].split(' ', 1)[0]\n","                    candidate_samples = self.negative_samples[int(user_id) - 1].split(' ', 1)[1].split(' ')\n","                else:\n","                    raise NotImplementedError\n","                candidate_samples.extend([target_item])\n","                random.shuffle(candidate_samples)\n","                rand_prob = random.random()\n","                if rand_prob > 0.5:\n","                    source_text = task_template['source'].format(user_id, ' , '.join(purchase_history),\n","                                                                 ' , '.join(candidate_samples))\n","                else:\n","                    source_text = task_template['source'].format(user_id, ' -> '.join(purchase_history),\n","                                                                 ' , '.join(candidate_samples))\n","                target_text = task_template['target'].format(target_item)\n","            elif task_template['id'] == '2-8' or task_template['id'] == '2-10':\n","                if self.mode in ['train', 'val']:\n","                    user_seq = self.user_items[user_id]\n","                    candidate_samples = []\n","                    candidate_num = random.randint(79, 99)\n","                    while len(candidate_samples) < candidate_num:\n","                        if self.sample_type == 'random':\n","                            sample_ids = np.random.choice(self.all_item, candidate_num, replace=False)\n","                        else:\n","                            sample_ids = np.random.choice(self.all_item, candidate_num, replace=False,\n","                                                          p=self.probability)\n","                        sample_ids = [str(item) for item in sample_ids if\n","                                      item not in user_seq and item not in candidate_samples]\n","                        candidate_samples.extend(sample_ids)\n","                    candidate_samples = candidate_samples[:candidate_num]\n","                elif self.mode == 'test':\n","                    assert user_id == self.negative_samples[int(user_id) - 1].split(' ', 1)[0]\n","                    candidate_samples = self.negative_samples[int(user_id) - 1].split(' ', 1)[1].split(' ')\n","                else:\n","                    raise NotImplementedError\n","                candidate_samples.extend([target_item])\n","                random.shuffle(candidate_samples)\n","                rand_prob = random.random()\n","                if rand_prob > 0.5:\n","                    source_text = task_template['source'].format(user_desc, ' , '.join(purchase_history),\n","                                                                 ' , '.join(candidate_samples))\n","                else:\n","                    source_text = task_template['source'].format(user_desc, ' -> '.join(purchase_history),\n","                                                                 ' , '.join(candidate_samples))\n","                target_text = task_template['target'].format(target_item)\n","            elif task_template['id'] == '2-11':\n","                symbol_prob = random.random()\n","                if symbol_prob > 0.5:\n","                    symbol = ' , '\n","                else:\n","                    symbol = ' -> '\n","                rand_prob = random.random()\n","                if rand_prob > 0.5:\n","                    source_text = task_template['source'].format(user_id, symbol.join(purchase_history), target_item)\n","                    target_text = task_template['target'].format('yes')\n","                else:\n","                    user_seq = self.user_items[user_id]\n","                    candidate_samples = []\n","                    candidate_num = 1\n","                    while len(candidate_samples) < candidate_num:\n","                        if self.sample_type == 'random':\n","                            sample_ids = np.random.choice(self.all_item, candidate_num, replace=False)\n","                        else:\n","                            sample_ids = np.random.choice(self.all_item, candidate_num, replace=False,\n","                                                          p=self.probability)\n","                        sample_ids = [str(item) for item in sample_ids if\n","                                      item not in user_seq and item not in candidate_samples]\n","                        candidate_samples.extend(sample_ids)\n","                    candidate_samples = candidate_samples[:candidate_num]\n","                    source_text = task_template['source'].format(user_id, symbol.join(purchase_history),\n","                                                                 candidate_samples[0])\n","                    target_text = task_template['target'].format('no')\n","            elif task_template['id'] == '2-12':\n","                symbol_prob = random.random()\n","                if symbol_prob > 0.5:\n","                    symbol = ' , '\n","                else:\n","                    symbol = ' -> '\n","                rand_prob = random.random()\n","                if rand_prob > 0.5:\n","                    source_text = task_template['source'].format(user_desc, symbol.join(purchase_history), target_item)\n","                    target_text = task_template['target'].format('yes')\n","                else:\n","                    user_seq = self.user_items[user_id]\n","                    candidate_samples = []\n","                    candidate_num = 1\n","                    while len(candidate_samples) < candidate_num:\n","                        if self.sample_type == 'random':\n","                            sample_ids = np.random.choice(self.all_item, candidate_num, replace=False)\n","                        else:\n","                            sample_ids = np.random.choice(self.all_item, candidate_num, replace=False,\n","                                                          p=self.probability)\n","                        sample_ids = [str(item) for item in sample_ids if\n","                                      item not in user_seq and item not in candidate_samples]\n","                        candidate_samples.extend(sample_ids)\n","                    candidate_samples = candidate_samples[:candidate_num]\n","                    source_text = task_template['source'].format(user_desc, symbol.join(purchase_history),\n","                                                                 candidate_samples[0])\n","                    target_text = task_template['target'].format('no')\n","            elif task_template['id'] == '2-13':\n","                rand_prob = random.random()\n","                if rand_prob > 0.5:\n","                    source_text = task_template['source'].format(user_desc, ' , '.join(purchase_history))\n","                else:\n","                    source_text = task_template['source'].format(user_desc, ' -> '.join(purchase_history))\n","                target_text = task_template['target'].format(target_item)\n","            else:\n","                raise NotImplementedError\n","\n","        elif task_name == 'explanation':\n","            exp_datum = self.exp_data[datum_idx]\n","            task_candidates = self.task_list[task_name]\n","            task_idx = random.randint(0, len(task_candidates) - 1)  # random choose the task index for task_candidates\n","            task_template = self.all_tasks['explanation'][task_candidates[task_idx]]\n","            assert task_template['task'] == 'explanation'\n","\n","            if task_template['id'] == '3-1':\n","                if 'name' in self.meta_data[self.meta_dict[exp_datum['asin']]]:\n","                    title = self.meta_data[self.meta_dict[exp_datum['asin']]]['name']\n","                else:\n","                    title = 'unknown name'\n","                source_text = task_template['source'].format(self.user2id[exp_datum['reviewerID']], title)\n","                target_text = task_template['target'].format(exp_datum['explanation'])\n","            elif task_template['id'] == '3-2':\n","                if 'name' in self.meta_data[self.meta_dict[exp_datum['asin']]]:\n","                    title = self.meta_data[self.meta_dict[exp_datum['asin']]]['name']\n","                else:\n","                    title = 'unknown name'\n","                source_text = task_template['source'].format(self.user2id[exp_datum['reviewerID']],\n","                                                             int(exp_datum['overall']), title)\n","                target_text = task_template['target'].format(exp_datum['explanation'])\n","            elif task_template['id'] == '3-3':\n","                if 'name' in self.user_data[self.user_meta_dict[exp_datum['reviewerID']]]:\n","                    user_desc = self.user_data[self.user_meta_dict[exp_datum['reviewerID']]]['name']\n","                else:\n","                    user_desc = exp_datum['reviewerID']\n","                if 'name' in self.meta_data[self.meta_dict[exp_datum['asin']]]:\n","                    title = self.meta_data[self.meta_dict[exp_datum['asin']]]['name']\n","                else:\n","                    title = 'unknown name'\n","                source_text = task_template['source'].format(user_desc, title)\n","                target_text = task_template['target'].format(exp_datum['explanation'])\n","            elif task_template['id'] == '3-4':\n","                if 'name' in self.user_data[self.user_meta_dict[exp_datum['reviewerID']]]:\n","                    user_desc = self.user_data[self.user_meta_dict[exp_datum['reviewerID']]]['name']\n","                else:\n","                    user_desc = exp_datum['reviewerID']\n","                source_text = task_template['source'].format(user_desc, int(exp_datum['overall']),\n","                                                             self.item2id[exp_datum['asin']])\n","                target_text = task_template['target'].format(exp_datum['explanation'])\n","            elif task_template['id'] == '3-5':\n","                source_text = task_template['source'].format(exp_datum['feature'],\n","                                                             self.user2id[exp_datum['reviewerID']],\n","                                                             self.item2id[exp_datum['asin']])\n","                target_text = task_template['target'].format(self.gaussian_sampling(exp_datum),\n","                                                             exp_datum['explanation'])\n","            elif task_template['id'] == '3-6':\n","                if 'name' in self.user_data[self.user_meta_dict[exp_datum['reviewerID']]]:\n","                    user_desc = self.user_data[self.user_meta_dict[exp_datum['reviewerID']]]['name']\n","                else:\n","                    user_desc = exp_datum['reviewerID']\n","                source_text = task_template['source'].format(user_desc, self.item2id[exp_datum['asin']])\n","                target_text = task_template['target'].format(self.gaussian_sampling(exp_datum),\n","                                                             exp_datum['explanation'])\n","            elif task_template['id'] == '3-7':\n","                if 'name' in self.meta_data[self.meta_dict[exp_datum['asin']]]:\n","                    title = self.meta_data[self.meta_dict[exp_datum['asin']]]['name']\n","                else:\n","                    title = 'unknown name'\n","                source_text = task_template['source'].format(exp_datum['feature'],\n","                                                             self.user2id[exp_datum['reviewerID']], title)\n","                target_text = task_template['target'].format(exp_datum['explanation'])\n","            elif task_template['id'] == '3-8':\n","                if 'name' in self.user_data[self.user_meta_dict[exp_datum['reviewerID']]]:\n","                    user_desc = self.user_data[self.user_meta_dict[exp_datum['reviewerID']]]['name']\n","                else:\n","                    user_desc = exp_datum['reviewerID']\n","                if 'name' in self.meta_data[self.meta_dict[exp_datum['asin']]]:\n","                    title = self.meta_data[self.meta_dict[exp_datum['asin']]]['name']\n","                else:\n","                    title = 'unknown name'\n","                source_text = task_template['source'].format(exp_datum['feature'], user_desc, title)\n","                target_text = task_template['target'].format(exp_datum['explanation'])\n","            elif task_template['id'] == '3-9':\n","                source_text = task_template['source'].format(exp_datum['feature'], int(exp_datum['overall']),\n","                                                             self.user2id[exp_datum['reviewerID']],\n","                                                             self.item2id[exp_datum['asin']])\n","                target_text = task_template['target'].format(exp_datum['explanation'])\n","            elif task_template['id'] == '3-10':\n","                if 'name' in self.user_data[self.user_meta_dict[exp_datum['reviewerID']]]:\n","                    user_desc = self.user_data[self.user_meta_dict[exp_datum['reviewerID']]]['name']\n","                else:\n","                    user_desc = exp_datum['reviewerID']\n","                source_text = task_template['source'].format(exp_datum['feature'], int(exp_datum['overall']), user_desc,\n","                                                             self.item2id[exp_datum['asin']])\n","                target_text = task_template['target'].format(exp_datum['explanation'])\n","            else:\n","                raise NotImplementedError\n","\n","        elif task_name == 'review':\n","            review_datum = self.review_data[datum_idx]\n","            task_candidates = self.task_list[task_name]\n","            task_idx = random.randint(0, len(task_candidates) - 1)  # random choose the task index for task_candidates\n","            task_template = self.all_tasks['review'][task_candidates[task_idx]]\n","            assert task_template['task'] == 'review'\n","\n","            if task_template['id'] == '4-1':\n","                source_text = task_template['source'].format(self.user2id[review_datum['reviewerID']],\n","                                                             review_datum['reviewText'])\n","                target_text = task_template['target'].format(int(review_datum['overall']))\n","            elif task_template['id'] == '4-2':\n","                source_text = task_template['source'].format(self.user2id[review_datum['reviewerID']],\n","                                                             review_datum['reviewText'])\n","                target_text = task_template['target'].format(int(review_datum['overall']))\n","            elif task_template['id'] == '4-3':\n","                if 'name' in self.user_data[self.user_meta_dict[review_datum['reviewerID']]]:\n","                    user_desc = self.user_data[self.user_meta_dict[review_datum['reviewerID']]]['name']\n","                else:\n","                    user_desc = review_datum['reviewerID']\n","                source_text = task_template['source'].format(user_desc, review_datum['reviewText'])\n","                target_text = task_template['target'].format(int(review_datum['overall']))\n","            else:\n","                raise NotImplementedError\n","\n","        elif task_name == 'traditional':\n","            sequential_datum = self.sequential_data[datum_idx]\n","            sequence = sequential_datum.split()\n","            user_id = sequence[0]\n","            user_desc = self.user_id2name[user_id]\n","            if self.mode == 'train':\n","                target_candidates = sequence[1:-2]\n","                target_idx = random.randint(0,\n","                                            len(target_candidates) - 1)  # random choose the target index for target_candidates\n","                target_item = target_candidates[target_idx]\n","            elif self.mode == 'val':\n","                target_item = sequence[-2]\n","            elif self.mode == 'test':\n","                target_item = sequence[-1]\n","            else:\n","                raise NotImplementedError\n","\n","            task_candidates = self.task_list[task_name]\n","            task_idx = random.randint(0, len(task_candidates) - 1)  # random choose the task index for task_candidates\n","            task_template = self.all_tasks['traditional'][task_candidates[task_idx]]\n","            assert task_template['task'] == 'traditional'\n","\n","            if task_template['id'] == '5-1':\n","                rand_prob = random.random()\n","                if rand_prob > 0.5:\n","                    source_text = task_template['source'].format(user_id, target_item)\n","                    target_text = task_template['target'].format('yes')\n","                else:\n","                    user_seq = self.user_items[user_id]\n","                    candidate_samples = []\n","                    candidate_num = 1\n","                    while len(candidate_samples) < candidate_num:\n","                        if self.sample_type == 'random':\n","                            sample_ids = np.random.choice(self.all_item, candidate_num, replace=False)\n","                        else:\n","                            sample_ids = np.random.choice(self.all_item, candidate_num, replace=False,\n","                                                          p=self.probability)\n","                        sample_ids = [str(item) for item in sample_ids if\n","                                      item not in user_seq and item not in candidate_samples]\n","                        candidate_samples.extend(sample_ids)\n","                    candidate_samples = candidate_samples[:candidate_num]\n","                    source_text = task_template['source'].format(user_id, candidate_samples[0])\n","                    target_text = task_template['target'].format('no')\n","            elif task_template['id'] == '5-2':\n","                rand_prob = random.random()\n","                if rand_prob > 0.5:\n","                    source_text = task_template['source'].format(target_item, user_desc)\n","                    target_text = task_template['target'].format('yes')\n","                else:\n","                    user_seq = self.user_items[user_id]\n","                    candidate_samples = []\n","                    candidate_num = 1\n","                    while len(candidate_samples) < candidate_num:\n","                        if self.sample_type == 'random':\n","                            sample_ids = np.random.choice(self.all_item, candidate_num, replace=False)\n","                        else:\n","                            sample_ids = np.random.choice(self.all_item, candidate_num, replace=False,\n","                                                          p=self.probability)\n","                        sample_ids = [str(item) for item in sample_ids if\n","                                      item not in user_seq and item not in candidate_samples]\n","                        candidate_samples.extend(sample_ids)\n","                    candidate_samples = candidate_samples[:candidate_num]\n","                    source_text = task_template['source'].format(candidate_samples[0], user_desc)\n","                    target_text = task_template['target'].format('no')\n","            elif task_template['id'] == '5-3':\n","                rand_prob = random.random()\n","                if rand_prob > 0.5:\n","                    if 'name' in self.meta_data[self.meta_dict[self.id2item[target_item]]]:\n","                        title = self.meta_data[self.meta_dict[self.id2item[target_item]]]['name']\n","                    else:\n","                        title = 'unknown name'\n","                    source_text = task_template['source'].format(user_desc, title)\n","                    target_text = task_template['target'].format('yes')\n","                else:\n","                    user_seq = self.user_items[user_id]\n","                    candidate_samples = []\n","                    candidate_num = 1\n","                    while len(candidate_samples) < candidate_num:\n","                        if self.sample_type == 'random':\n","                            sample_ids = np.random.choice(self.all_item, candidate_num, replace=False)\n","                        else:\n","                            sample_ids = np.random.choice(self.all_item, candidate_num, replace=False,\n","                                                          p=self.probability)\n","                        sample_ids = [str(item) for item in sample_ids if\n","                                      item not in user_seq and item not in candidate_samples]\n","                        candidate_samples.extend(sample_ids)\n","                    candidate_samples = candidate_samples[:candidate_num]\n","                    if 'name' in self.meta_data[self.meta_dict[self.id2item[candidate_samples[0]]]]:\n","                        title = self.meta_data[self.meta_dict[self.id2item[candidate_samples[0]]]]['name']\n","                    else:\n","                        title = 'unknown name'\n","                    source_text = task_template['source'].format(user_desc, title)\n","                    target_text = task_template['target'].format('no')\n","            elif task_template['id'] == '5-4':\n","                rand_prob = random.random()\n","                if rand_prob > 0.5:\n","                    if 'name' in self.meta_data[self.meta_dict[self.id2item[target_item]]]:\n","                        title = self.meta_data[self.meta_dict[self.id2item[target_item]]]['name']\n","                    else:\n","                        title = 'unknown name'\n","                    source_text = task_template['source'].format(user_id, title)\n","                    target_text = task_template['target'].format('yes')\n","                else:\n","                    user_seq = self.user_items[user_id]\n","                    candidate_samples = []\n","                    candidate_num = 1\n","                    while len(candidate_samples) < candidate_num:\n","                        if self.sample_type == 'random':\n","                            sample_ids = np.random.choice(self.all_item, candidate_num, replace=False)\n","                        else:\n","                            sample_ids = np.random.choice(self.all_item, candidate_num, replace=False,\n","                                                          p=self.probability)\n","                        sample_ids = [str(item) for item in sample_ids if\n","                                      item not in user_seq and item not in candidate_samples]\n","                        candidate_samples.extend(sample_ids)\n","                    candidate_samples = candidate_samples[:candidate_num]\n","                    if 'name' in self.meta_data[self.meta_dict[self.id2item[candidate_samples[0]]]]:\n","                        title = self.meta_data[self.meta_dict[self.id2item[candidate_samples[0]]]]['name']\n","                    else:\n","                        title = 'unknown name'\n","                    source_text = task_template['source'].format(user_id, title)\n","                    target_text = task_template['target'].format('no')\n","            elif task_template['id'] == '5-5' or task_template['id'] == '5-6':\n","                user_seq = self.user_items[user_id]\n","                candidate_samples = []\n","                candidate_num = 99  # random.randint(19, 99)\n","                while len(candidate_samples) < candidate_num:\n","                    if self.sample_type == 'random':\n","                        sample_ids = np.random.choice(self.all_item, candidate_num, replace=False)\n","                    else:\n","                        sample_ids = np.random.choice(self.all_item, candidate_num, replace=False, p=self.probability)\n","                    sample_ids = [str(item) for item in sample_ids if\n","                                  item not in user_seq and item not in candidate_samples]\n","                    candidate_samples.extend(sample_ids)\n","                candidate_samples = candidate_samples[:candidate_num]\n","                candidate_samples.extend([target_item])\n","                random.shuffle(candidate_samples)\n","                source_text = task_template['source'].format(user_desc, ' , '.join(candidate_samples))\n","                target_text = task_template['target'].format(target_item)\n","            elif task_template['id'] == '5-7' or task_template['id'] == '5-8':\n","                user_seq = self.user_items[user_id]\n","                candidate_samples = []\n","                candidate_num = 99  # random.randint(19, 99)\n","                while len(candidate_samples) < candidate_num:\n","                    if self.sample_type == 'random':\n","                        sample_ids = np.random.choice(self.all_item, candidate_num, replace=False)\n","                    else:\n","                        sample_ids = np.random.choice(self.all_item, candidate_num, replace=False, p=self.probability)\n","                    sample_ids = [str(item) for item in sample_ids if\n","                                  item not in user_seq and item not in candidate_samples]\n","                    candidate_samples.extend(sample_ids)\n","                candidate_samples = candidate_samples[:candidate_num]\n","                candidate_samples.extend([target_item])\n","                random.shuffle(candidate_samples)\n","                source_text = task_template['source'].format(user_id, ' , '.join(candidate_samples))\n","                target_text = task_template['target'].format(target_item)\n","            else:\n","                raise NotImplementedError\n","\n","        else:\n","            raise NotImplementedError\n","\n","        input_ids = self.tokenizer.encode(source_text, padding=True, truncation=True, max_length=self.args.max_text_length)\n","        tokenized_text = self.tokenizer.tokenize(source_text)\n","        whole_word_ids = self.calculate_whole_word_ids(tokenized_text, input_ids)\n","        assert len(whole_word_ids) == len(input_ids)\n","\n","        target_ids = self.tokenizer.encode(target_text, padding=True, truncation=True, max_length=self.args.gen_max_length)\n","\n","        out_dict['idx'] = idx\n","        out_dict['input_ids'] = torch.LongTensor(input_ids)\n","        out_dict['input_length'] = len(input_ids)\n","        out_dict['whole_word_ids'] = torch.LongTensor(whole_word_ids)\n","        out_dict['target_ids'] = torch.LongTensor(target_ids)\n","        out_dict['target_length'] = len(target_ids)\n","\n","        out_dict['source_text'] = source_text\n","        out_dict['tokenized_text'] = tokenized_text\n","        out_dict['target_text'] = target_text\n","\n","        out_dict['task'] = task_template['task']\n","\n","        out_dict['loss_weight'] = loss_weight\n","\n","        return out_dict\n","\n","\n","\n","def get_data(args, task_list, sample_numbers, mode='train'):\n","\n","    tokenizer = CustomTokenizer.from_pretrained(\n","        args.model_name,\n","        max_length = args.max_text_length,\n","        do_lower_case = args.do_lower_case\n","    )\n","\n","    dataset = P5YelpDataset(\n","        task_templates,\n","        task_list,\n","        tokenizer,\n","        args,\n","        sample_numbers,\n","        mode=mode,\n","        rating_augment=False\n","    )\n","\n","    if mode == 'train':\n","        loader = DataLoader(\n","            dataset,\n","            batch_size=args.batch_size,\n","            shuffle=False,\n","            num_workers=16,\n","            pin_memory=True,\n","            collate_fn=dataset.collate_fn)\n","    else:\n","        loader = DataLoader(\n","            dataset,\n","            batch_size=args.batch_size,\n","            num_workers=16,\n","            pin_memory=True,\n","            shuffle=False,\n","            collate_fn=dataset.collate_fn,\n","            drop_last=False)\n","\n","    return loader"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"T3CzkadLbmxD"},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"id":"izvhQftKbnGZ"},"source":["#### Build Model"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"YEIfq4BmbqBS"},"outputs":[],"source":["@dataclass\n","class P5Seq2SeqLMOutput(ModelOutput):\n","    loss: Optional[torch.FloatTensor] = None\n","    logits: torch.FloatTensor = None\n","    past_key_values: Optional[List[torch.FloatTensor]] = None\n","    decoder_last_hidden_state: Optional[Tuple[torch.FloatTensor]] = None\n","    decoder_hidden_states: Optional[Tuple[torch.FloatTensor]] = None\n","    decoder_attentions: Optional[Tuple[torch.FloatTensor]] = None\n","    encoder_last_hidden_state: Optional[torch.FloatTensor] = None\n","    encoder_hidden_states: Optional[Tuple[torch.FloatTensor]] = None\n","    encoder_attentions: Optional[Tuple[torch.FloatTensor]] = None\n","\n","\n","\n","class JointEncoder(T5Stack):\n","\n","    def __init__(self, config, embed_tokens=None):\n","        super(T5Stack, self).__init__(config)\n","        self.config = config\n","        self.embed_tokens = embed_tokens\n","        self.is_decoder = self.config.is_decoder\n","        assert self.config.is_decoder is False\n","\n","        self.block = nn.ModuleList(\n","            [T5Block(config, has_relative_attention_bias=(i == 0)) for i in range(config.num_layers)]\n","        )\n","        self.final_layer_norm = T5LayerNorm(config.d_model, eps=config.layer_norm_epsilon)\n","        self.dropout = nn.Dropout(config.dropout_rate)\n","\n","        ## Set maximum 512 whole words in a source text\n","        self.whole_word_embeddings = nn.Embedding(512, config.d_model) ## config.d_model is 768 for base\n","        self.init_weights()\n","\n","    def set_input_embeddings(self, new_embeddings):\n","        self.embed_tokens = new_embeddings\n","\n","    def forward(\n","        self,\n","        input_ids=None,\n","        attention_mask=None,\n","        encoder_hidden_states=None,\n","        encoder_attention_mask=None,\n","        inputs_embeds=None,\n","        head_mask=None,\n","        cross_attn_head_mask=None,\n","        past_key_values=None,\n","        use_cache=None,\n","        output_attentions=None,\n","        output_hidden_states=None,\n","        return_dict=None,\n","        cache_position=None,\n","        whole_word_ids=None,\n","    ):\n","\n","        # input_ids = input_ids.to(DEVICE)\n","        # attention_mask = attention_mask.to(DEVICE)\n","        # if labels is not None:\n","        #     labels = labels.to(DEVICE)\n","\n","        if inputs_embeds is None:\n","            assert self.embed_tokens is not None, \"You have to initialize the model with valid token embeddings\"\n","            inputs_embeds = self.embed_tokens(input_ids)  ### embedding step - add HERE ###\n","            if whole_word_ids is not None:\n","                whole_word_embeds = self.whole_word_embeddings(whole_word_ids)\n","                assert whole_word_embeds.shape[-1] == inputs_embeds.shape[-1]\n","                inputs_embeds = inputs_embeds + whole_word_embeds\n","\n","        B, L = inputs_embeds.size()[:-1]\n","\n","        if attention_mask is None:\n","            attention_mask = input_ids.ne(self.config.pad_token_id).to(dtype=inputs_embeds.dtype, device=DEVICE)\n","\n","        # ourselves in which case we just need to make it broadcastable to all heads.\n","        extended_attention_mask = self.get_extended_attention_mask(attention_mask,(B, L), DEVICE)\n","\n","        # initialize past_key_values with `None` if past does not exist\n","        if past_key_values is None:\n","            past_key_values = [None] * len(self.block)\n","\n","        # Prepare head mask if needed\n","        head_mask = self.get_head_mask(head_mask, self.config.num_layers)\n","        present_key_value_states = () if use_cache else None\n","        all_hidden_states = () if output_hidden_states else None\n","        all_attentions = () if output_attentions else None\n","        all_cross_attentions = () if (output_attentions and self.is_decoder) else None\n","\n","        hidden_states = self.dropout(inputs_embeds)\n","\n","        if self.config.num_layers > 0:\n","            assert self.block[0].layer[0].SelfAttention.has_relative_attention_bias\n","\n","            seq_length = L\n","            q_len = seq_length\n","            k_len = seq_length\n","\n","            # [1, n_heads, Q_len, K_len]\n","            text_position_bias = self.block[0].layer[0].SelfAttention.compute_bias(L, L)\n","            num_heads = text_position_bias.size(1)\n","            position_bias = text_position_bias.new_zeros(1, num_heads, seq_length, seq_length)\n","            position_bias[:, :, :L, :L] = text_position_bias\n","\n","            position_bias = position_bias + extended_attention_mask\n","\n","            for i, (layer_module, past_key_value) in enumerate(zip(self.block, past_key_values)):\n","                layer_outputs = layer_module(\n","                    hidden_states,\n","                    attention_mask=extended_attention_mask,\n","                    position_bias=position_bias,\n","                    encoder_hidden_states=None,\n","                    encoder_attention_mask=None,\n","                    encoder_decoder_position_bias=None,\n","                    layer_head_mask=head_mask[i],\n","                    past_key_value=past_key_value,\n","                    use_cache=use_cache,\n","                    output_attentions=output_attentions,\n","                )\n","\n","                if len(layer_outputs)==2:\n","                    hidden_states, position_bias = layer_outputs\n","                elif len(layer_outputs)==3:\n","                    hidden_states, present_key_value_state, position_bias = layer_outputs\n","                else:\n","                    raise ValueError(\"layer_outputs does not have proper length\")\n","\n","                # append next layer key value states\n","                if use_cache:\n","                    present_key_value_states = present_key_value_states + (present_key_value_state,)\n","\n","        hidden_states = self.final_layer_norm(hidden_states)\n","        hidden_states = self.dropout(hidden_states)\n","\n","        # Add last layer\n","        if output_hidden_states:\n","            all_hidden_states = all_hidden_states + (hidden_states,)\n","\n","        if not return_dict:\n","            return tuple(\n","                v\n","                for v in [\n","                    hidden_states,\n","                    present_key_value_states,\n","                    all_hidden_states,\n","                    all_attentions,\n","                    all_cross_attentions,\n","                ]\n","                if v is not None\n","            )\n","        return BaseModelOutputWithPastAndCrossAttentions(\n","            last_hidden_state=hidden_states,\n","            past_key_values=present_key_value_states,\n","            hidden_states=all_hidden_states,\n","            attentions=all_attentions,\n","            cross_attentions=all_cross_attentions,\n","        )\n","\n","\n","\n","class P5(T5ForConditionalGeneration):\n","\n","    def __init__(self, config):\n","        super(T5ForConditionalGeneration, self).__init__(config)\n","        self.config = config\n","        self.model_dim = config.d_model\n","        self.shared = nn.Embedding(config.vocab_size, config.d_model)\n","\n","        encoder_config = copy.deepcopy(config)\n","        encoder_config.is_decoder = False\n","        encoder_config.use_cache = False\n","        encoder_config.is_encoder_decoder = False\n","        self.encoder = JointEncoder(encoder_config, self.shared)\n","\n","        decoder_config = copy.deepcopy(config)\n","        decoder_config.is_decoder = True\n","        decoder_config.is_encoder_decoder = False\n","        self.decoder = T5Stack(decoder_config, self.shared)\n","\n","        self.lm_head = nn.Linear(config.d_model, config.vocab_size, bias=False)\n","        self.init_weights()\n","\n","    def set_input_embeddings(self, new_embeddings):\n","        self.shared = new_embeddings\n","        self.encoder.set_input_embeddings(new_embeddings)\n","        self.decoder.set_input_embeddings(new_embeddings)\n","\n","    def extend_vocab(self, vocab_size):\n","        new_shared = nn.Embedding(vocab_size, self.config.d_model)\n","        old_weight = self.shared.weight.data.detach().clone()\n","        old_vocab_size = old_weight.size(0)\n","        new_shared.weight.data[:old_vocab_size, :] = old_weight\n","        self.shared = new_shared\n","\n","        new_lm_head = nn.Linear(self.config.d_model, vocab_size, bias=False)\n","        old_weight = self.lm_head.weight.data.detach().clone()\n","        old_vocab_size = old_weight.size(0)\n","        new_lm_head.weight.data[:old_vocab_size, :] = old_weight\n","        self.lm_head = new_lm_head\n","\n","        self.encoder.embed_tokens = self.shared\n","        self.decoder.embed_tokens = self.shared\n","        self.lm_head.weight = self.shared.weight\n","        self.config.vocab_size = vocab_size\n","        self.encoder.config.vocab_size = vocab_size\n","        self.decoder.config.vocab_size = vocab_size\n","\n","    def forward(\n","        self,\n","        input_ids=None,\n","        whole_word_ids=None,\n","        attention_mask=None,\n","        encoder_outputs=None,\n","        decoder_input_ids=None,\n","        decoder_attention_mask=None,\n","        past_key_values=None,\n","        use_cache=None,\n","        labels=None,\n","        inputs_embeds=None,\n","        decoder_inputs_embeds=None,\n","        head_mask=None,\n","        output_attentions=None,\n","        output_hidden_states=None,\n","        return_dict=None,\n","        reduce_loss=False,\n","        return_hidden_state=False,\n","        **kwargs,\n","    ):\n","\n","        use_cache = use_cache if use_cache is not None else self.config.use_cache\n","        return_dict = return_dict if return_dict is not None else self.config.use_return_dict\n","\n","        input_ids = input_ids.to(DEVICE)\n","        if attention_mask is not None:\n","            attention_mask = attention_mask.to(DEVICE)\n","        if labels is not None:\n","            labels = labels.to(DEVICE)\n","\n","        if encoder_outputs is None:\n","            encoder_outputs = self.encoder(\n","                input_ids=input_ids,\n","                whole_word_ids=whole_word_ids,\n","                attention_mask=attention_mask,\n","                inputs_embeds=inputs_embeds,\n","                head_mask=head_mask,\n","                output_attentions=output_attentions,\n","                output_hidden_states=output_hidden_states,\n","                return_dict=return_dict,\n","            )\n","        elif return_dict and not isinstance(encoder_outputs, BaseModelOutput):\n","            encoder_outputs = BaseModelOutput(\n","                last_hidden_state=encoder_outputs[0],\n","                hidden_states=encoder_outputs[1] if len(encoder_outputs) > 1 else None,\n","                attentions=encoder_outputs[2] if len(encoder_outputs) > 2 else None,\n","            )\n","\n","        hidden_states = encoder_outputs[0]\n","\n","        if labels is not None and decoder_input_ids is None and decoder_inputs_embeds is None:\n","            # get decoder inputs from shifting lm labels to the right\n","            decoder_input_ids = self._shift_right(labels)\n","\n","        # If decoding with past key value states, only the last tokens\n","        # should be given as an input\n","        if past_key_values is not None:\n","            assert labels is None, \"Decoder should not use cached key value states when training.\"\n","            if decoder_input_ids is not None:\n","                decoder_input_ids = decoder_input_ids[:, -1:]\n","            if decoder_inputs_embeds is not None:\n","                decoder_inputs_embeds = decoder_inputs_embeds[:, -1:]\n","\n","        if attention_mask is None:\n","            attention_mask = input_ids.ne(self.config.pad_token_id).to(dtype=hidden_states.dtype, device=hidden_states.device)\n","        encoder_attention_mask = attention_mask\n","\n","        # Decode\n","        decoder_outputs = self.decoder(\n","            input_ids=decoder_input_ids,\n","            attention_mask=decoder_attention_mask,\n","            inputs_embeds=decoder_inputs_embeds,\n","            past_key_values=past_key_values,\n","\n","            encoder_hidden_states=hidden_states,\n","            encoder_attention_mask=encoder_attention_mask,\n","\n","            head_mask=head_mask,\n","            use_cache=use_cache,\n","            output_attentions=output_attentions,\n","            output_hidden_states=output_hidden_states,\n","            return_dict=return_dict,\n","        )\n","\n","        sequence_output = decoder_outputs[0]\n","\n","        assert self.config.tie_word_embeddings is True\n","\n","        if self.config.tie_word_embeddings:\n","            sequence_output = sequence_output * (self.model_dim ** -0.5)\n","\n","        if return_hidden_state:\n","            return sequence_output\n","\n","        lm_logits = self.lm_head(sequence_output)\n","\n","        loss = None\n","        if labels is not None:\n","            if reduce_loss:\n","                loss_fct = CrossEntropyLoss(ignore_index=-100)\n","            else:\n","                loss_fct = CrossEntropyLoss(ignore_index=-100, reduction='none')\n","            loss = loss_fct(\n","                lm_logits.view(-1, lm_logits.size(-1)),\n","                labels.view(-1))\n","\n","        return P5Seq2SeqLMOutput(\n","            loss=loss,\n","            logits=lm_logits,\n","            past_key_values=decoder_outputs.past_key_values,\n","            decoder_last_hidden_state=decoder_outputs.last_hidden_state,\n","            decoder_hidden_states=decoder_outputs.hidden_states,\n","        )\n","\n","    def prepare_inputs_for_generation(\n","        self, input_ids, past=None, attention_mask=None, use_cache=None,\n","        encoder_outputs=None,\n","        **kwargs):\n","\n","        if past is not None:\n","            input_ids = input_ids[:, -1:]\n","\n","        output = {\n","            \"decoder_input_ids\": input_ids,\n","            \"past_key_values\": past,\n","            \"encoder_outputs\": encoder_outputs,\n","            \"attention_mask\": attention_mask,\n","            \"use_cache\": use_cache,\n","        }\n","\n","        return output\n","\n","    @staticmethod\n","    def _expand_inputs_for_generation(\n","        input_ids: torch.LongTensor,\n","        expand_size: int = 1,\n","        is_encoder_decoder: bool = False,\n","        attention_mask: torch.LongTensor = None,\n","        encoder_outputs: ModelOutput = None,\n","        **model_kwargs\n","    ) -> Tuple[torch.LongTensor, Dict[str, Any]]:\n","        expanded_return_idx = (\n","            torch.arange(input_ids.shape[0]).view(-1, 1).repeat(1,\n","                                                                expand_size).view(-1).to(input_ids.device)\n","        )\n","        input_ids = input_ids.index_select(0, expanded_return_idx)\n","\n","        if \"token_type_ids\" in model_kwargs:\n","            token_type_ids = model_kwargs[\"token_type_ids\"]\n","            model_kwargs[\"token_type_ids\"] = token_type_ids.index_select(\n","                0, expanded_return_idx)\n","\n","        if attention_mask is not None:\n","            model_kwargs[\"attention_mask\"] = attention_mask.index_select(\n","                0, expanded_return_idx)\n","\n","        if is_encoder_decoder:\n","            assert encoder_outputs is not None\n","            encoder_outputs[\"last_hidden_state\"] = encoder_outputs.last_hidden_state.index_select(0, expanded_return_idx)\n","            model_kwargs[\"encoder_outputs\"] = encoder_outputs\n","\n","        return input_ids, model_kwargs"]},{"cell_type":"markdown","metadata":{"id":"N6jG3o6JbrBe"},"source":["#### Trainer Base"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"DPkFXgZvbyEA"},"outputs":[],"source":["class TrainerBase(object):\n","    def __init__(self, args, train_loader=None, val_loader=None, test_loader=None, train=True):\n","        self.args = args\n","        self.train_loader = train_loader\n","        self.val_loader = val_loader\n","        self.test_loader = test_loader\n","        self.verbose = True\n","        if self.args.tokenizer is None:\n","            self.args.tokenizer = self.args.model_name\n","        if not self.verbose:\n","            set_global_logging_level(logging.ERROR, [\"transformers\"])\n","\n","    def create_config(self):\n","        config_class = T5Config\n","        config = config_class.from_pretrained(self.args.model_name)\n","        args = self.args\n","        config.dropout_rate = args.dropout\n","        config.dropout = args.dropout\n","        config.attention_dropout = args.dropout\n","        config.activation_dropout = args.dropout\n","        config.losses = args.losses\n","        return config\n","\n","    def create_model(self, model_class, config=None, **kwargs):\n","        model_name = self.args.model_name\n","        model = model_class.from_pretrained(\n","            model_name,\n","            config=config,\n","            **kwargs\n","        )\n","        return model\n","\n","    def create_tokenizer(self, **kwargs):\n","        tokenizer_class = CustomTokenizer\n","        tokenizer_name = self.args.model_name\n","        tokenizer = tokenizer_class.from_pretrained(\n","            tokenizer_name,\n","            max_length=self.args.max_text_length,\n","            do_lower_case=self.args.do_lower_case,\n","            **kwargs\n","            )\n","        return tokenizer\n","\n","    def create_optimizer_and_scheduler(self):\n","        if self.verbose:\n","            print('Building Optimizer')\n","        lr_scheduler = None\n","\n","        batch_per_epoch = len(self.train_loader)\n","        t_total = batch_per_epoch // self.args.gradient_accumulation_steps * self.args.epoch\n","        warmup_ratio = self.args.warmup_ratio\n","        warmup_iters = int(t_total * warmup_ratio)\n","        if self.verbose:\n","            print(\"Batch per epoch: %d\" % batch_per_epoch)\n","            print(\"Total Iters: %d\" % t_total)\n","            print('Warmup ratio:', warmup_ratio)\n","            print(\"Warm up Iters: %d\" % warmup_iters)\n","\n","        no_decay = [\"bias\", \"LayerNorm.weight\"]\n","        optimizer_grouped_parameters = [\n","            {\n","                \"params\": [p for n, p in self.model.named_parameters() if not any(nd in n for nd in no_decay)],\n","                \"weight_decay\": self.args.weight_decay,\n","            },\n","            {\n","                \"params\": [p for n, p in self.model.named_parameters() if any(nd in n for nd in no_decay)],\n","                \"weight_decay\": 0.0,\n","            },\n","        ]\n","        optim = AdamW(optimizer_grouped_parameters, lr=self.args.lr, eps=self.args.adam_eps)\n","        lr_scheduler = get_linear_schedule_with_warmup(optim, warmup_iters, t_total)\n","\n","        return optim, lr_scheduler\n","\n","    def load_checkpoint(self, ckpt_path):\n","        state_dict = load_state_dict(ckpt_path, 'cpu')\n","        results = self.model.load_state_dict(state_dict, strict=False)\n","        if self.verbose:\n","            print('Model loaded from ', ckpt_path)\n","            pprint(results)\n","\n","    def init_weights(self):\n","\n","        def init_bert_weights(module):\n","            \"\"\" Initialize the weights.\"\"\"\n","            if isinstance(module, (nn.Linear, nn.Embedding)):\n","                module.weight.data.normal_(mean=0.0, std=1)\n","            elif isinstance(module, nn.LayerNorm):\n","                module.bias.data.zero_()\n","                module.weight.data.fill_(1.0)\n","            if isinstance(module, nn.Linear) and module.bias is not None:\n","                module.bias.data.zero_()\n","        self.model.apply(init_bert_weights)\n","        self.model.init_weights()\n","\n","    def predict(self):\n","        pass\n","\n","    def evaluate(self):\n","        pass\n","\n","    def save(self, name):\n","        if not os.path.isdir(self.args.output):\n","            os.makedirs(self.args.output, exist_ok=True)\n","        torch.save(self.model.state_dict(), os.path.join(self.args.output, \"%s.pth\" % name))\n","\n","    def load(self, path, loc=None):\n","        if loc is None and hasattr(self.args, 'gpu'):\n","            loc = f'cuda:{self.args.gpu}'\n","        state_dict = torch.load(\"%s.pth\" % path, map_location=loc)\n","        results = self.model.load_state_dict(state_dict, strict=False)\n","        if self.verbose:\n","            print('Model loaded from ', path)\n","            pprint(results)\n","\n","\n","class P5Pretraining(P5):\n","    def __init__(self, config):\n","        super().__init__(config)\n","        self.losses = self.config.losses\n","\n","    def train_step(self, batch):\n","        input_ids = batch['input_ids'].to(DEVICE)\n","        whole_word_ids = batch['whole_word_ids'].to(DEVICE)\n","        lm_labels = batch[\"target_ids\"].to(DEVICE)\n","        loss_weights = batch[\"loss_weights\"].to(DEVICE)\n","        output = self(\n","            input_ids=input_ids,\n","            whole_word_ids=whole_word_ids,\n","            labels=lm_labels,\n","            return_dict=True\n","        )\n","        assert 'loss' in output\n","\n","        lm_mask = lm_labels != -100\n","        lm_mask = lm_mask.float()\n","        B, L = lm_labels.size()\n","        loss = output['loss']\n","        loss = loss.view(B, L) * lm_mask\n","        loss = loss.sum(dim=1) / lm_mask.sum(dim=1).clamp(min=1)\n","\n","        task_counts = {task: 0 for task in self.losses}\n","        task_loss = {task: 0 for task in self.losses}\n","\n","        results = {}\n","        results['loss'] = (loss * loss_weights).mean()\n","        results['total_loss'] = loss.detach().sum()\n","        results['total_loss_count'] = len(loss)\n","\n","        task_counts = {task.replace(\"_loss\", \"\"): 0 for task in self.losses}\n","        task_loss = {task.replace(\"_loss\", \"\"): 0 for task in self.losses}\n","        for _loss, task in zip(loss.detach(), batch['task']):\n","            task_loss[task] += _loss\n","            task_counts[task] += 1\n","        for task in self.losses:\n","            task = task.replace(\"_loss\", \"\")\n","            if task_counts[task] > 0:\n","                results[f'{task}'] = task_loss[task]\n","                results[f'{task}_count'] = task_counts[task]\n","\n","        return results\n","\n","    @torch.no_grad()\n","    def valid_step(self, batch):\n","        self.eval()\n","        input_ids = batch['input_ids'].to(DEVICE)\n","        lm_labels = batch[\"target_ids\"].to(DEVICE)\n","        loss_weights = batch[\"loss_weights\"].to(DEVICE)\n","        output = self(\n","            input_ids=input_ids,\n","            labels=lm_labels,\n","            return_dict=True\n","        )\n","        assert 'loss' in output\n","\n","        lm_mask = lm_labels != -100\n","        lm_mask = lm_mask.float()\n","        B, L = lm_labels.size()\n","        loss = output['loss']\n","        loss = loss.view(B, L) * lm_mask\n","        loss = loss.sum(dim=1) / lm_mask.sum(dim=1).clamp(min=1)\n","\n","        results = {}\n","        results['loss'] = (loss * loss_weights).mean()\n","        results['total_loss'] = loss.detach().sum()\n","        results['total_loss_count'] = len(loss)\n","\n","        task_counts = {task: 0 for task in self.losses}\n","        task_loss = {task: 0 for task in self.losses}\n","        for _loss, task in zip(loss.detach(), batch['task']):\n","            task_loss[task] += _loss\n","            task_counts[task] += 1\n","        for task in self.losses:\n","            if task_counts[task] > 0:\n","                results[f'{task}'] = task_loss[task]\n","                results[f'{task}_count'] = task_counts[task]\n","\n","        if 'rating' in self.losses:\n","            output = self.generate(input_ids=input_ids)\n","            generated_score = self.tokenizer.batch_decode(output, skip_special_tokens=True)\n","            results['rating_pred'] = generated_score\n","\n","        return results\n","\n","    @torch.no_grad()\n","    def generate_step(self, batch):\n","        self.eval()\n","        input_ids = batch['input_ids'].to(DEVICE)\n","        output = self.generate(input_ids=input_ids)\n","        generated_sents = self.tokenizer.batch_decode(output, skip_special_tokens=True)\n","        return generated_sents\n","\n","\n","\n","class Trainer(TrainerBase):\n","    def __init__(self, args, train_loader=None, val_loader=None, test_loader=None, train=True):\n","        super().__init__(args, train_loader=train_loader, val_loader=val_loader, test_loader=test_loader, train=train)\n","        assert args.whole_word_embed\n","\n","        model_kwargs = {}\n","        model_class = P5Pretraining\n","\n","        config = self.create_config()\n","        self.tokenizer = self.create_tokenizer()\n","        self.model = self.create_model(model_class, config, **model_kwargs)\n","        if 'p5' in self.args.tokenizer:\n","            self.model.resize_token_embeddings(self.tokenizer.vocab_size)\n","        self.model.tokenizer = self.tokenizer\n","\n","        # Load Checkpoint\n","        self.start_epoch = None\n","        # if args.load is not None:\n","        #     ckpt_path = args.load + '.pth'\n","        #     self.load_checkpoint(ckpt_path)\n","        #     self.start_epoch = int(args.load.split('Epoch-')[-1])\n","\n","        # if self.args.from_scratch:\n","        #     self.init_weights()\n","        self.init_weights()\n","\n","        # GPU Options\n","        # print(f'Model Launching at GPU {self.args.gpu}')\n","        # if self.verbose:\n","        #     from time import time\n","        #     start = time()\n","        # self.model = self.model.to(args.gpu)\n","        self.model = self.model.to(DEVICE)\n","\n","        # Optimizer\n","        if train:\n","            self.optim, self.lr_scheduler = self.create_optimizer_and_scheduler()\n","\n","        # if self.verbose:\n","        #     print(f'It took {time() - start:.1f}s')\n","\n","    def train(self):\n","        LOSSES_NAME = self.args.losses\n","\n","        if self.verbose:\n","            loss_meters = [LossMeter() for _ in range(len(LOSSES_NAME))]\n","            best_eval_loss = 100000.\n","\n","        global_step = 0\n","        for epoch in range(self.args.epoch):\n","            self.model.train()\n","            pbar = tqdm(total=len(self.train_loader), ncols=275)\n","\n","            epoch_results = {}\n","            for loss_name in LOSSES_NAME:\n","                epoch_results[loss_name] = 0.\n","                epoch_results[f'{loss_name}_count'] = 0\n","\n","            for step_i, batch in enumerate(self.train_loader):\n","                results = self.model.train_step(batch)\n","                loss = results['loss']\n","                loss.backward()\n","                loss = loss.detach()\n","                self.optim.step()\n","                if self.lr_scheduler:\n","                    self.lr_scheduler.step()\n","                # self.model.zero_grad()\n","                for param in self.model.parameters():\n","                    param.grad = None\n","                global_step += 1\n","                lr = self.lr_scheduler.get_lr()[0]\n","\n","                for k, v in results.items():\n","                    if k in epoch_results:\n","                        if isinstance(v, int):\n","                            epoch_results[k] += v\n","                        elif isinstance(v, torch.Tensor):\n","                            epoch_results[k] += v.item()\n","\n","                if step_i % 20000:\n","                    desc_str = f'Epoch {epoch} | LR {lr:.6f} |'\n","                    for i, (loss_name, loss_meter) in enumerate(zip(LOSSES_NAME, loss_meters)):\n","                        if loss_name in results:\n","                            loss_meter.update(results[f'{loss_name}'] / results[f'{loss_name}_count'])\n","                        if len(loss_meter) > 0:\n","                            loss_count = epoch_results[f'{loss_name}_count']\n","                            desc_str += f' {loss_name} ({loss_count}) {loss_meter.val:.3f}'\n","                    pbar.set_description(desc_str)\n","                    pbar.update(1)\n","\n","\n","            pbar.close()\n","            results = sum(epoch_results) / len(epoch_results)\n","            train_loss = results['total_loss']\n","            train_loss_count = results['total_loss_count']\n","            avg_train_loss = train_loss / train_loss_count\n","            losses_str = f\"Train Loss: {avg_train_loss:.3f}\\n\"\n","\n","            for name, loss in results.items():\n","                if name[-4:] == 'loss':\n","                    loss_count = int(results[name+'_count'])\n","                    if loss_count > 0:\n","                        avg_loss = loss/loss_count\n","                        losses_str += f\"{name} ({loss_count}): {avg_loss:.3f} \"\n","            losses_str += '\\n'\n","            print(losses_str)"]},{"cell_type":"markdown","metadata":{"id":"WyS3eS2uby54"},"source":["#### Train"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":874,"referenced_widgets":["d0fa25942ff64ae0b4510a9fdcebd12c","d48289a41011459d91706c5df943c7a6","440b6c609f0c4878963146f923f46896","09b89c1bc9d64352a731ff9b0bd9916a","eacc0e7b3b9e4b3289065165ccf042c9","0a243bbb0d18488d8d1022aa353f5a96","fd62ab8ce7954bd5892a0c32031c0432","088d0d3dbb85494d935d3f7fb4b72bc0","8129bd0d81284a59bc2b76a3731e2696","f477607615ad4a66b14360fb9b0aa499","f13f75e4453d4214990d6ed758589487","dd16902e069a4c3e9cf60c60acfa3929","4d2952414e994fcb9b29aedc98ce4432","2b688814cc8c4994a0fc7af766f4ad43","20c1667193a6427683ab99e1fdd6350b","7dbcd7d1aa754b9d849c5128396a1fc3","9f1b426776a241fc908d5fc3f5d11469","6ee576e9e47b42b18f816e709737fc3d","527a3c5caca147e8b34260f3e0ab570d","564272436afd45edb95a068b13b58948","0997ac12df1f49548fcb98bd4ee44bb2","fd155a8d88154f8bbc0f887550948186","11954d6488e64fc88e3e0a3b265c7bfd","56456a656db942a3a341c8518efe9a95","6fee4b4a8e2a4662a35baeb6739dfbfe","42ca57462e4b40d593e9c4736a8c19e0","8f3cbcfe8320412e8f15e21aeac48f5e","3eaa7dc046b54d7bb73b4d37847e2a42","dc0328b0a89e4036919b083412450b79","c1da07710298478dbf14f34e37977024","432993a638da45a7a48ecec992976a8e","a1a4f93389e04a4cac57d7bb46641263","1e418e8f2a834762a066d077cd40af49","d89a3993397b4e719430d16129e1e3a7","97b57c1a2690475d8dac4fa086f49c34","639e60ddd3e34fc4a545405234ce9c86","0f00aba737a746f1b9b60270e0c9e2da","9389b9fcd1e84f73889352b3b117fc8e","c78f9a70f4b448569df741478816c31a","48fe40bf2977453cbedc5bb2262deeef","857053cdae16422db57c7ed75de6dcf0","f32ba9688d1648f7aaac4342b240c664","d8e0961ea6b3466bb4cfc905c2b7e32b","f0eb8c9f366f49aead1a60cb860d1597","b8b368caaec5480dbfd94e5f7b50d259","652d12354c324fa38997303a079562a2","ed891c456b43462697942173077517c1","d68278915a0245b2bcb4b12a61cc2818","86cbbe78b1924b909e070ec0f53e1ca9","a3a9a0b6aaf44819bc6bc4120e6a934c","e2672a152e464084bbcba7348abcbf0e","e576f92ef6b54ca9b8474c5550d27b68","5128f2e6279944288681b955f42cea7a","6724fb6ace7e48ab986d67f80b9e665b","f54a30bc4380484d9f4892510d3c15cf"]},"id":"ZRK1e2tob0N2","outputId":"feae2ae3-9e82-4a88-a091-e72a0aa6f85d"},"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n","The secret `HF_TOKEN` does not exist in your Colab secrets.\n","To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n","You will be able to reuse this secret in all of your notebooks.\n","Please note that authentication is recommended but still optional to access public models or datasets.\n","  warnings.warn(\n"]},{"output_type":"display_data","data":{"text/plain":["spiece.model:   0%|          | 0.00/792k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d0fa25942ff64ae0b4510a9fdcebd12c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["tokenizer.json:   0%|          | 0.00/1.39M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"dd16902e069a4c3e9cf60c60acfa3929"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["config.json:   0%|          | 0.00/1.21k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"11954d6488e64fc88e3e0a3b265c7bfd"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n","The tokenizer class you load from this checkpoint is 'T5Tokenizer'. \n","The class this function is called from is 'CustomTokenizer'.\n","You are using the default legacy behaviour of the <class '__main__.CustomTokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thoroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n"]},{"output_type":"stream","name":"stdout","text":["Total number of businesses: stored in self.meta_dict 20033\n","Total umber of users: stored in self.user_meta_dict 30431\n","compute_datum_info\n","Init call finished\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 16 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  warnings.warn(\n","The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n","The tokenizer class you load from this checkpoint is 'T5Tokenizer'. \n","The class this function is called from is 'CustomTokenizer'.\n"]},{"output_type":"stream","name":"stdout","text":["Total number of businesses: stored in self.meta_dict 20033\n","Total umber of users: stored in self.user_meta_dict 30431\n","compute_datum_info\n","Init call finished\n"]},{"output_type":"stream","name":"stderr","text":["The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n","The tokenizer class you load from this checkpoint is 'T5Tokenizer'. \n","The class this function is called from is 'CustomTokenizer'.\n"]},{"output_type":"display_data","data":{"text/plain":["model.safetensors:   0%|          | 0.00/892M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d89a3993397b4e719430d16129e1e3a7"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Some weights of P5Pretraining were not initialized from the model checkpoint at t5-base and are newly initialized: ['encoder.whole_word_embeddings.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"display_data","data":{"text/plain":["generation_config.json:   0%|          | 0.00/147 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b8b368caaec5480dbfd94e5f7b50d259"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/transformers/optimization.py:591: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["Building Optimizer\n","Batch per epoch: 441316\n","Total Iters: 441316\n","Warmup ratio: 0.05\n","Warm up Iters: 22065\n"]},{"output_type":"stream","name":"stderr","text":["\r  0%|                                                                                                                                                                                                                                                   | 0/441316 [00:00<?, ?it/s]/usr/local/lib/python3.11/dist-packages/transformers/modeling_utils.py:1044: FutureWarning: The `device` argument is deprecated and will be removed in v5 of Transformers.\n","  warnings.warn(\n","Passing a tuple of `past_key_values` is deprecated and will be removed in Transformers v4.48.0. You should pass an instance of `EncoderDecoderCache` instead, e.g. `past_key_values=EncoderDecoderCache.from_legacy_cache(past_key_values)`.\n","Epoch 0 | LR 0.000244 | total_loss (21576) 2.654:   1%|██▏                                                                                                                                                                                | 5393/441316 [16:15<24:55:51,  4.86it/s]"]}],"source":["def main_train(args):\n","    train_task_list = {'rating': ['1-1', '1-2', '1-3', '1-4', '1-5', '1-6', '1-7', '1-8', '1-9'],\n","                       'sequential': ['2-1', '2-2', '2-3', '2-4', '2-5', '2-6', '2-7', '2-8', '2-9', '2-10', '2-11', '2-12'],\n","                       'explanation': ['3-1', '3-2', '3-3', '3-4', '3-5', '3-6', '3-7', '3-8', '3-9'],\n","                       'review': ['4-1', '4-2'],\n","                       'traditional': ['5-1', '5-2', '5-3', '5-4', '5-5', '5-6', '5-7']\n","                       }\n","    train_sample_numbers = {'rating': 1, 'sequential': (5, 5, 10), 'explanation': 1, 'review': 1, 'traditional': (10, 5)}\n","    train_loader = get_data(\n","        args,\n","        train_task_list,\n","        train_sample_numbers,\n","        mode='train',\n","    )\n","\n","\n","    val_task_list = {'rating': ['1-1', '1-2', '1-3', '1-4', '1-5', '1-6', '1-7', '1-8', '1-9'],\n","    'sequential': ['2-1', '2-2', '2-3', '2-4', '2-5', '2-6', '2-7', '2-8', '2-9', '2-10', '2-11', '2-12'],\n","    'explanation': ['3-1', '3-2', '3-3', '3-4', '3-5', '3-6', '3-7', '3-8', '3-9'],\n","    'review': ['4-1', '4-2'],\n","    'traditional': ['5-1', '5-2', '5-3', '5-4', '5-5', '5-6', '5-7']\n","    }\n","    val_sample_numbers = {'rating': 1, 'sequential': (1, 1, 1), 'explanation': 1, 'review': 1, 'traditional': (1, 1)}\n","    val_loader = get_data(\n","        args,\n","        val_task_list,\n","        val_sample_numbers,\n","        mode='val',\n","    )\n","\n","    # for batch_idx, (inputs, targets) in enumerate(train_loader):\n","    #     print(batch_idx, inputs, targets)\n","    #     break\n","    # print(\"here\")\n","\n","    trainer = Trainer(args, train_loader, val_loader, train=True)\n","    trainer.train()\n","\n","\n","\n","if __name__ == \"__main__\":\n","    args = ModelParams\n","\n","    # set random state\n","    torch.manual_seed(args.seed)\n","    random.seed(args.seed)\n","    np.random.seed(args.seed)\n","    main_train(args)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"wOWHOIk7cpHv"},"outputs":[],"source":[]}],"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyMs58LIlEYEaWmlSu7CEJVq"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"d0fa25942ff64ae0b4510a9fdcebd12c":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_d48289a41011459d91706c5df943c7a6","IPY_MODEL_440b6c609f0c4878963146f923f46896","IPY_MODEL_09b89c1bc9d64352a731ff9b0bd9916a"],"layout":"IPY_MODEL_eacc0e7b3b9e4b3289065165ccf042c9"}},"d48289a41011459d91706c5df943c7a6":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_0a243bbb0d18488d8d1022aa353f5a96","placeholder":"​","style":"IPY_MODEL_fd62ab8ce7954bd5892a0c32031c0432","value":"spiece.model: 100%"}},"440b6c609f0c4878963146f923f46896":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_088d0d3dbb85494d935d3f7fb4b72bc0","max":791656,"min":0,"orientation":"horizontal","style":"IPY_MODEL_8129bd0d81284a59bc2b76a3731e2696","value":791656}},"09b89c1bc9d64352a731ff9b0bd9916a":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_f477607615ad4a66b14360fb9b0aa499","placeholder":"​","style":"IPY_MODEL_f13f75e4453d4214990d6ed758589487","value":" 792k/792k [00:00&lt;00:00, 1.24MB/s]"}},"eacc0e7b3b9e4b3289065165ccf042c9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0a243bbb0d18488d8d1022aa353f5a96":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"fd62ab8ce7954bd5892a0c32031c0432":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"088d0d3dbb85494d935d3f7fb4b72bc0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8129bd0d81284a59bc2b76a3731e2696":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"f477607615ad4a66b14360fb9b0aa499":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f13f75e4453d4214990d6ed758589487":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"dd16902e069a4c3e9cf60c60acfa3929":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_4d2952414e994fcb9b29aedc98ce4432","IPY_MODEL_2b688814cc8c4994a0fc7af766f4ad43","IPY_MODEL_20c1667193a6427683ab99e1fdd6350b"],"layout":"IPY_MODEL_7dbcd7d1aa754b9d849c5128396a1fc3"}},"4d2952414e994fcb9b29aedc98ce4432":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_9f1b426776a241fc908d5fc3f5d11469","placeholder":"​","style":"IPY_MODEL_6ee576e9e47b42b18f816e709737fc3d","value":"tokenizer.json: 100%"}},"2b688814cc8c4994a0fc7af766f4ad43":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_527a3c5caca147e8b34260f3e0ab570d","max":1389353,"min":0,"orientation":"horizontal","style":"IPY_MODEL_564272436afd45edb95a068b13b58948","value":1389353}},"20c1667193a6427683ab99e1fdd6350b":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_0997ac12df1f49548fcb98bd4ee44bb2","placeholder":"​","style":"IPY_MODEL_fd155a8d88154f8bbc0f887550948186","value":" 1.39M/1.39M [00:00&lt;00:00, 1.64MB/s]"}},"7dbcd7d1aa754b9d849c5128396a1fc3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9f1b426776a241fc908d5fc3f5d11469":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6ee576e9e47b42b18f816e709737fc3d":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"527a3c5caca147e8b34260f3e0ab570d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"564272436afd45edb95a068b13b58948":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"0997ac12df1f49548fcb98bd4ee44bb2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"fd155a8d88154f8bbc0f887550948186":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"11954d6488e64fc88e3e0a3b265c7bfd":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_56456a656db942a3a341c8518efe9a95","IPY_MODEL_6fee4b4a8e2a4662a35baeb6739dfbfe","IPY_MODEL_42ca57462e4b40d593e9c4736a8c19e0"],"layout":"IPY_MODEL_8f3cbcfe8320412e8f15e21aeac48f5e"}},"56456a656db942a3a341c8518efe9a95":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_3eaa7dc046b54d7bb73b4d37847e2a42","placeholder":"​","style":"IPY_MODEL_dc0328b0a89e4036919b083412450b79","value":"config.json: 100%"}},"6fee4b4a8e2a4662a35baeb6739dfbfe":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_c1da07710298478dbf14f34e37977024","max":1208,"min":0,"orientation":"horizontal","style":"IPY_MODEL_432993a638da45a7a48ecec992976a8e","value":1208}},"42ca57462e4b40d593e9c4736a8c19e0":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_a1a4f93389e04a4cac57d7bb46641263","placeholder":"​","style":"IPY_MODEL_1e418e8f2a834762a066d077cd40af49","value":" 1.21k/1.21k [00:00&lt;00:00, 98.5kB/s]"}},"8f3cbcfe8320412e8f15e21aeac48f5e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3eaa7dc046b54d7bb73b4d37847e2a42":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"dc0328b0a89e4036919b083412450b79":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"c1da07710298478dbf14f34e37977024":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"432993a638da45a7a48ecec992976a8e":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"a1a4f93389e04a4cac57d7bb46641263":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1e418e8f2a834762a066d077cd40af49":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"d89a3993397b4e719430d16129e1e3a7":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_97b57c1a2690475d8dac4fa086f49c34","IPY_MODEL_639e60ddd3e34fc4a545405234ce9c86","IPY_MODEL_0f00aba737a746f1b9b60270e0c9e2da"],"layout":"IPY_MODEL_9389b9fcd1e84f73889352b3b117fc8e"}},"97b57c1a2690475d8dac4fa086f49c34":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_c78f9a70f4b448569df741478816c31a","placeholder":"​","style":"IPY_MODEL_48fe40bf2977453cbedc5bb2262deeef","value":"model.safetensors: 100%"}},"639e60ddd3e34fc4a545405234ce9c86":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_857053cdae16422db57c7ed75de6dcf0","max":891646390,"min":0,"orientation":"horizontal","style":"IPY_MODEL_f32ba9688d1648f7aaac4342b240c664","value":891646390}},"0f00aba737a746f1b9b60270e0c9e2da":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_d8e0961ea6b3466bb4cfc905c2b7e32b","placeholder":"​","style":"IPY_MODEL_f0eb8c9f366f49aead1a60cb860d1597","value":" 892M/892M [00:04&lt;00:00, 91.8MB/s]"}},"9389b9fcd1e84f73889352b3b117fc8e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c78f9a70f4b448569df741478816c31a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"48fe40bf2977453cbedc5bb2262deeef":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"857053cdae16422db57c7ed75de6dcf0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f32ba9688d1648f7aaac4342b240c664":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"d8e0961ea6b3466bb4cfc905c2b7e32b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f0eb8c9f366f49aead1a60cb860d1597":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"b8b368caaec5480dbfd94e5f7b50d259":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_652d12354c324fa38997303a079562a2","IPY_MODEL_ed891c456b43462697942173077517c1","IPY_MODEL_d68278915a0245b2bcb4b12a61cc2818"],"layout":"IPY_MODEL_86cbbe78b1924b909e070ec0f53e1ca9"}},"652d12354c324fa38997303a079562a2":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_a3a9a0b6aaf44819bc6bc4120e6a934c","placeholder":"​","style":"IPY_MODEL_e2672a152e464084bbcba7348abcbf0e","value":"generation_config.json: 100%"}},"ed891c456b43462697942173077517c1":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_e576f92ef6b54ca9b8474c5550d27b68","max":147,"min":0,"orientation":"horizontal","style":"IPY_MODEL_5128f2e6279944288681b955f42cea7a","value":147}},"d68278915a0245b2bcb4b12a61cc2818":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_6724fb6ace7e48ab986d67f80b9e665b","placeholder":"​","style":"IPY_MODEL_f54a30bc4380484d9f4892510d3c15cf","value":" 147/147 [00:00&lt;00:00, 9.54kB/s]"}},"86cbbe78b1924b909e070ec0f53e1ca9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a3a9a0b6aaf44819bc6bc4120e6a934c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e2672a152e464084bbcba7348abcbf0e":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"e576f92ef6b54ca9b8474c5550d27b68":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5128f2e6279944288681b955f42cea7a":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"6724fb6ace7e48ab986d67f80b9e665b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f54a30bc4380484d9f4892510d3c15cf":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"nbformat":4,"nbformat_minor":0}